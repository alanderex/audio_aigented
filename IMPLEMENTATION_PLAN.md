# ğŸ—ï¸ Core ASR Transcription Pipeline - Implementation Plan

## ğŸ“ Architecture Overview

```mermaid
graph LR
    A[Audio Files<br/>.wav] --> B[Audio Loader]
    B --> C[ASR Transcriber<br/>NVIDIA NeMo]
    C --> D[Output Formatter]
    D --> E[File Writer]
    E --> F[Results<br/>JSON + TXT]
    
    G[Config YAML] --> B
    G --> C
    G --> D
    G --> E
    
    subgraph "Pipeline Stages"
        B
        C
        D
        E
    end
```

## ğŸ§© Core Components

| Component | Purpose | Key Features |
|-----------|---------|--------------|
| **Audio Loader** | Load and prepare `.wav` files | Resampling, validation, batching |
| **ASR Transcriber** | Speech-to-text conversion | NVIDIA NeMo integration, GPU optimization |
| **Output Formatter** | Structure transcription results | Timestamps, confidence scores, metadata |
| **File Writer** | Save processed results | JSON/TXT output, directory creation |
| **Config Manager** | Handle YAML configurations | OmegaConf integration, validation |
| **Main Pipeline** | Orchestrate processing stages | Error handling, logging, caching |

## ğŸ“ Project Structure

```
audio_aigented/
â”œâ”€â”€ src/
â”‚   â””â”€â”€ audio_aigented/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ audio/
â”‚       â”‚   â”œâ”€â”€ __init__.py
â”‚       â”‚   â””â”€â”€ loader.py          # Audio file loading & preprocessing
â”‚       â”œâ”€â”€ transcription/
â”‚       â”‚   â”œâ”€â”€ __init__.py
â”‚       â”‚   â””â”€â”€ asr.py             # NVIDIA NeMo ASR integration
â”‚       â”œâ”€â”€ formatting/
â”‚       â”‚   â”œâ”€â”€ __init__.py
â”‚       â”‚   â””â”€â”€ formatter.py       # Output structuring
â”‚       â”œâ”€â”€ output/
â”‚       â”‚   â”œâ”€â”€ __init__.py
â”‚       â”‚   â””â”€â”€ writer.py          # File writing (JSON/TXT)
â”‚       â”œâ”€â”€ config/
â”‚       â”‚   â”œâ”€â”€ __init__.py
â”‚       â”‚   â””â”€â”€ manager.py         # Configuration management
â”‚       â”œâ”€â”€ models/
â”‚       â”‚   â”œâ”€â”€ __init__.py
â”‚       â”‚   â””â”€â”€ schemas.py         # Pydantic data models
â”‚       â””â”€â”€ pipeline.py            # Main pipeline orchestration
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ test_audio/
â”‚   â”œâ”€â”€ test_transcription/
â”‚   â”œâ”€â”€ test_formatting/
â”‚   â”œâ”€â”€ test_output/
â”‚   â””â”€â”€ test_pipeline.py
â”œâ”€â”€ config/
â”‚   â””â”€â”€ default.yaml               # Default configuration
â”œâ”€â”€ examples/
â”‚   â”œâ”€â”€ sample_audio/
â”‚   â””â”€â”€ basic_usage.py
â”œâ”€â”€ inputs/                        # Default input directory for .wav files
â”œâ”€â”€ outputs/                       # Default output directory structure
â”‚   â””â”€â”€ [audio_filename]/          # Per-file output directories
â”‚       â”œâ”€â”€ transcript.json        # Structured transcription data
â”‚       â””â”€â”€ transcript.txt         # Human-readable transcript
â”œâ”€â”€ cache/                         # ASR model and processing cache
â”œâ”€â”€ main.py                        # CLI entry point
â”œâ”€â”€ pyproject.toml                 # Dependencies & project config
â””â”€â”€ README.md                      # Documentation
```

## ğŸ“‚ Directory Management Strategy

### Input Directory Structure
- **Default Location**: `./inputs/`
- **File Pattern**: `*.wav` files in the input directory
- **Validation**: Check file existence, format, and audio properties
- **Scanning**: Recursive scanning with configurable depth

### Output Directory Structure
- **Default Location**: `./outputs/`
- **Per-File Directories**: Each audio file gets its own subdirectory
- **Naming Convention**: `[audio_filename_without_extension]/`
- **Contents**:
  - `transcript.json` - Structured transcription with timestamps, confidence scores
  - `transcript.txt` - Human-readable transcript format

### Example Directory Layout
```
inputs/
â”œâ”€â”€ meeting_recording.wav
â”œâ”€â”€ interview_audio.wav
â””â”€â”€ conference_call.wav

outputs/
â”œâ”€â”€ meeting_recording/
â”‚   â”œâ”€â”€ transcript.json
â”‚   â””â”€â”€ transcript.txt
â”œâ”€â”€ interview_audio/
â”‚   â”œâ”€â”€ transcript.json
â”‚   â””â”€â”€ transcript.txt
â””â”€â”€ conference_call/
    â”œâ”€â”€ transcript.json
    â””â”€â”€ transcript.txt
```

## ï¿½ Implementation Steps

### Phase 1: Project Foundation
1. **Dependencies Setup** - Add NVIDIA NeMo, PyTorch, librosa, pydantic, omegaconf
2. **Data Models** - Create Pydantic schemas for transcription results
3. **Configuration System** - YAML-based config with OmegaConf
4. **Basic Project Structure** - Create module directories and `__init__.py` files

### Phase 2: Core Components
5. **Audio Loader** - `.wav` file loading, validation, resampling for NeMo compatibility
6. **ASR Transcriber** - NVIDIA NeMo integration with GPU optimization
7. **Output Formatter** - Structure results with timestamps and confidence scores
8. **File Writer** - Save JSON/TXT outputs with proper directory structure

### Phase 3: Pipeline Integration
9. **Main Pipeline** - Orchestrate all stages with error handling
10. **CLI Interface** - Command-line interface through `main.py`
11. **Caching System** - Cache ASR results to avoid re-processing
12. **Logging & Monitoring** - Comprehensive logging for debugging

### Phase 4: Testing & Documentation
13. **Unit Tests** - Pytest tests for each component (minimum 3 tests per module)
14. **Integration Tests** - End-to-end pipeline testing
15. **Documentation** - Update README with usage examples
16. **Example Scripts** - Demonstration scripts with sample audio

## âš™ï¸ Key Technical Details

### NVIDIA NeMo Integration
- Use pre-trained conformer models (e.g., `stt_en_conformer_ctc_large`)
- GPU acceleration with CUDA 12.8
- Batch processing for efficiency
- Automatic model caching

### Configuration Schema
```yaml
audio:
  sample_rate: 16000
  batch_size: 8
  
transcription:
  model_name: "stt_en_conformer_ctc_large"
  device: "cuda"
  enable_confidence_scores: true
  
output:
  format: ["json", "txt"]
  include_timestamps: true
  output_dir: "./outputs"
  
processing:
  enable_caching: true
  cache_dir: "./cache"
```

### Data Models
- `TranscriptionResult` - Complete transcription with metadata
- `AudioSegment` - Individual audio segments with timestamps
- `ProcessingConfig` - Configuration validation schema

## ğŸ¯ Success Criteria
- Successfully transcribe `.wav` files using NVIDIA NeMo
- Generate structured JSON and readable TXT outputs
- GPU-optimized processing with caching
- Comprehensive test coverage (>90%)
- Clear documentation and usage examples
- Modular, maintainable codebase (<500 lines per file)

## ğŸš€ Next Steps
Ready to switch to **Code Mode** for implementation starting with Phase 1: Project Foundation.
============================================================
AUDIO TRANSCRIPTION REPORT
============================================================
File: out_mono_How to build an AI-first organization.wav
Duration: 3619.70 seconds
Processed: 2025-06-15 08:23:57
Processing Time: 8.83s (Speed: 409.84x)
------------------------------------------------------------
FULL TRANSCRIPTION:

you can either fire most of your staff and make more money per barrel of ale or you can beginness and hire hundred thousand people expand worldwide and i really worry about too many people thinking the small path not the big one i would love to start from the very beginning when you were back at mit with you know the o and marvin minski and so on what were sort of the i b s at abot so this is a little bit of like stolen techno glory because i was not the coder with marvin i was the person in the nm b a program who was trying to help the a i people explain what i was to everybody else i work with marvin and a few other people at the media lab quite a bit on this and it what was really interesting was a lot you know this was sort of during one of the ma various i winters right so it was there was pay much attention to a i and it was all about sort of elaborate schemes for how we can create intelligence and so there was projects to observe everything a baby did and maybe that would somehow let us make a there was vermentsk society of mind of all these kind of complex interlocking pieces and i think about how kind of ironic it was that the actual solution turn out to be just shove a lot of language into a learning system and you end up with with l m it's interesting because a lot of the technical ideas turned out to to be incorrect but there was a lot of the core philosophies there that i think are are back in fashion now you had minsky and engelbart engelbart had this philosophy of augmenting human intelligence and minsky was a lot about replacing human intelligence and trying to make machines conscious what were some of those sort of foundational ideas of how it i could be applied than that you think can be relevant now i mean i think that's we're all kind of struggling with right now is now that we have these things in sight and we know we're back to what is aessenient and what are the t i mean i think was two weeks ago a new paper came out showing that the actual original turning test right gets passed the three party turing test the g b four point five is capable of passing it right and in fact seventy percent the time people will pick the a i as the human in the room which i don't know what that means w it's better than chance but that's interesting and so i think we're faced with all these exact set of issues that a few things are worrying about for a long time so does this replace humans and what do we use that for right and for augmentation what is augmentation look like becomes the big question right is it you know and we that that debate i think never got as far as as it could be first because this was still kind of fictional right so what do we do with these very intelligent also very limited machines and then where do humans fit into the equation i don't think it was ever answered and now it's only very very important and the churing test was it was a beautiful idea back back then but if we were to design a new test now a mol test what would be your molic test for g i so i i struggle with a g i a is this concept all the time right which is it's badly defined i mean the reason why turning test is interesting just like all the other test is they were great when we didn't have anything to test right like the turn is great when computers obviously failed it similarly have issues where the acing all the creativity tests we have but those were designed and they were always mediocre for humans and now we're expecting i to do them the way we figure out whether someone has empathy in social science is the the best test is of the called the reading the mind in the eyes test we show a bunch of eyes and ask what emotion they have like none of these things were designed for a i stuff so i think about this a lot and i'm ten be very practically oriented on this right so firs a everyone kind of has their own a g i s test you know i'm a business school professor some with some of the easiest is can this agent go in the world and make money and do things is a useful useful test can we discover new knowledge and actually test and come with results but i mean i think what we're starting to realize is a a g i is going to be this sort of phase we're in rather thn a moment in time right there's not going to be a you know fireworks going off tyler cohen just said three is a g i and when asked why he says it's like pornography i know when i see it and so we don't know what the answer to these questions are and i think it's kind of realizing the meaninglessness of it because it turns out also like as you guys have learned if you connect a i to systems in the right way and you connect the company processes sden you have something that's much better in the sum of its parts  something you're prompting you're just doing conversation and that's feels very different then can we do stret strateic decision making for example and frequently when this models are realist it's always on the most hardcore math problems and science problems it's it's very rarely the take more business applications if you were to decide sign a benchmark that was more focused on the applications that you see in companies what would a benchmark for that look like so i think that is one of the most critical problems we're facing right now because all of the people in the labs are math and science people and they view the only good thing you could do with your life is coding right and then add to that the fact that they want to use ai to make better a i and coding and math becomes like the important things followed by biology because they all want to live forever so like that becomes the angle that that this goes down and there are very few benchmarks other things so we know the ice companies build towards benchmarks a bll sketchy ways right of like optimizing for benchmarks but also in more broad ways of they use this for testing and so the fact the lack of good business benchmarks is a real problem so i i actually one thing i've been pushing is companies should be doing this themselves to some extent right like and some of this could be direct number based like how often does it mess up in being asked to do an accounting process but some of this is bvibes based as they say it would you actually could have outside experts we've done this for somemmer experiments judge the quality of answers and is this is good as a human or not have your own turning tests for various important parts of your job right is the analysis report good enough what's the error rate on it you know if we use this to give us to give a strategy advice how good is it how good is it a selection decision and those are questions are not that hard to measure right they're not that technical but they do require a little bit of effort i think that's that's one of the areas where products have been largely lacking too especially when you deploy agents the ability to test a agents and see what knowledge they have and what knowledge they're lacking and correct them and run this test sets has been really really limit limited so as we think about de signing and first org so you basically get a thousand in person company and you gets to real design that work to be completely how do you structure it so the first thing you say is redesigned to be i native is hard because it was 'an a i native right so we are we are in this really interesting spot where we've had basically hundreds of years of organizational development that is paralleled you know in es revolution the communication revolution i mean the first or chart came out in eight hundred fifty five for the ne in railroad and it solved a problem that never existed before which is how do we coordinate coordinate vast amounts of you know traffic on train lines in real time using a telegraph and they came up ckenzie the guy who came up with this came up with the or chart as a solution we still use them todayine hdd ten huge breakthroughs in organizing work henry ford's production lines time clocks still use those today early two thousand agile development right all of these things broke because they all depended on there being only one form of intelligence available which is human comes in human sized packages can only be deployed with a span of control of five or seven people you know two pizza problem and now we're in a world where that isn't the case so things have to be rebuilt from the ground up and i worry a little bit that modern western companies have given up an organizational innovation a something they do it used to be that the way dow chemical would win or the way that i b m would win would they' come with new approaches to sales or new approaches to work with organizations and now we've outsourced that so enterprise software companies will tell you how to build your company because sales force sells you a sales force product that tes you how you sales or a large scale consul the company will come come in and tell you how how your organization should run and now is a time where leaders actually need to innovate so if to return to your sort of core question it has to be building from both the idea that we're heading in in a trend line where humans are less necessary in the product and then where do you get you have to pick your whether you augmentation replacement and then you have to start building the systems from that fewer people doing more impressive work or more people doing ever more work and trying to take over the world together the this that we have have sort of fewer hundred x employees or do we sort of boost double the productivity of everyone do do create this sort of small clusters of folks that are overseeing the orchestration of agents and are you know orders of magnitude more more more productive or is it sort of more deployed horizontally across the organization where a few people get more more so i think those are hey choices i mean one of things i really worry about is when i look at early implementations what people view this is as an efficiency technology and i bear a little blame for that our earliert work focus on productivity gains from a i and i still focus on that because i matters but i worry a lot that at the edge of industrial revolution what we're seeing happen or some sort of new revolution what we're seeing happen right now is that companies are viewing this like a normal technology so they get a twenty five percent cost savings from you know or efficiency gain in customer service let's cut twenty five percent of people right like i hear that all the time and there's a whole bunch of dangers with that one of them is nobody knows how to deploy a i in your organization other than you right you can build tools and the techniques that are really useful but ultimately it has to people in the company that figure out is this good or bad they're the ones with the experience the evidence to do it if they're terrified of doing that because they'll get fired or punished for using ai or they'll be replaced beuse if there's efficiency gain they'll never show youun efficiency gain right and then the second set of problems around that is if we're really in a world we're about to see an explosion of performance of productivity the idea that you should be as small mean as possible going into that like it's like if you imagine in the early industrial revolution and you are you're a you know a local brewer in the early eight hundreds you get steam power you can either fire most of your staff make more money per barrel of ale or you beginness and hire on hundred thousand people expand worldwide and i really worry about too many people thinking the small path not the big one and you've generally advocated more for human augment and the idea that you know the back ino days weused to talk about bicycles for the mine and now we might be getting you know airplanes for the mine to some extent in what ways do you think this will be augmenting human human intelligence what because it's been quite counterintuitive what we thought historically was it would start with themn then repetitive tasks and then it would move on to knowledge work en coding and then the very last thing you would take would be the creative tasks but it's almost been like the exact opposite in the sense that you know the creative tasks the knowledge work but the then repetitive has been really tricky to ultimate so in what ways do you think we'll actually be implementing this i mean it is fascinating how much like everywhere you know the image of a i would be that if you taught if you tried to explain the concept love it would explode right does not compute instead we have these weird systems that are super emotional and have to be convinced to do things right like we've actually found imprompt engineering sometimes that what you have to do is actually just justify the i why it should do a step rather tell you do something like that this is why it's supported you should do it which which is super weird and so the thing to think about with augment though is that our jobs are that we do are bundles of many different tasks right nobody would have designed any job that we have i as a professor right when is to was to a good teacher and come with good ideas to be able to have a conversation with you and do research and run an academic department and you know like the one would e be a counselor right no one want all of these jobs and a lot of them are sort of hot as jobs i don't mind giving away grading to an a i right if that helps like i wouldn't mind providing more counseling support through a i if that helps even though they're very human kinds of things so i don't think that augmentation necessarily mean like just because it does creative engaging sort of human knowledge work tasks at least at the current levels were at it's definitely below the expert level in these kind of cases whever you're best st you're probably better than a i so the question become augmentation level one is just handoff stuff you're less good at as part of your job bundle and the second level is how do to use it to boost what you're doing right now and we're starying to get some good evidence for that too and what happens when the systems become more proactive than than really active we're so reliant on giving this systems input to what this should give back to us and prompting them and so on at some point we should be getting systems that are better than us at asking those questions too and can sort of proactively serve this to us is that something you're saying if you take your dom an examplef could go out and do all of the research for you and then come and sa sort of this this matches your research tt here are five papers i wrote pick the best one have you started seeing any applications like that yeah i mean there's a couple things you said there that are really important one of them is actually the more minor point which is the idea that it gives me ten papers to pick from right this idea of you know it ho we're now but abundance but we're not used to a situation where you can just get a lot of something and cure curate right so one of the things that actually matters a lot is taste and curation that i want to be able to pick out of a subset of options andn that still matters a lot that kind of taste piece or what to pursue and i startt management which is not the end of the world right like management is what most of us aspire to anyway right or at least a lot of people aspire to and it starts to be giving your direction taste where it goes but like i think at the end of this we don't know how good the systems get and that ultimately every question becomes downstream of how good you think i gets right if it's it's good enough that it does all of our work at the high level of what the work you do in your organization does the work that i do as a professor then you know we're sort of inan uncharted territory overall and i don't know what the answer is i think that real organizations are you know work much more in much more complex ways than we think about th i always aim for efficiency and i remains very jagged in its frontier of capability so it can't quite do the whole paper because parts of it all fail but i if i have experience i'll know where those fail and can intervene and shape those places just like i would with a ph d student so i think we're going to be a longer world of limit autonomy than people think where like direction guidance you know is still going to be important i think the jaged from tars is probably one of the areas that's most bot the lking organizations now it's so incredibly confusing talking to a system that sometimes is genius and sometimes it's completely stupid and it also makes it very difficult to deploy it on the dead in the organization a bit similarly we've had with self driving cars where the deployment took a very long time because it was both sort of superhuman in some applications and other in other situations get quite tripped up what do you think will will s in unided agents andw how they will be deployed wll will be you know bottlenecked for another decade by the jagged frontier or will we start trusting these systems and to d quite soon i mean i think we're already a place where narrow agents are very good right so the best example those are the deep research agents that now been rolled out by you know google open e and x right and their perplexi as well the they're all very good right and they do the narrow task of finding information being you know giving you answers very well and that is a highly remunerated task right and they're not quite there yet because they don't have access the kind of private data that people need to be able to use these systems fully but you know the' starting to get very good legal research accounting and market research and finance research and like so i think that they'll that kind of delegation to a fairly complex taest and narrow agents feels very doable i think there are clever ways to generalize agents with other agents watching them that no one's really pushing yet like we were so new into this that the that youre kind of have to make two bets right one is the whole of frintier when w i came with the idea of jagged front heer is like the frontier is constantly pushing out so it's jagged right some of those jgonis will stick around for a while some it doesn't matter if it's still bad at it because it's as the ays get better overall it's it still beats humans right and so i think part of this is the question do you wait for the frontier to move out and then solve the problems or do you build around them today and i think part of the key is doing both right of like how do we but if you invest too much on trying to solve the jagonist today as long as models keep getting better you end up stuck with a legacy system built around a jagged frontier that no longer exists makes makes a lot of sense and one thing that's organizations find it quite tricky is discovering that use cases and have some bottoms up strateges where effectively most parts of the organizations is already using this tools to some extent but just not telling their their leadership and then they have some top down initiatives where they're like let's build some i sd r sor whatever that that might be how would you approach you know discovering these use cases internally what are some tactics there so i tend to say you need three things to make a i work in  organization you need leadership lab and crowd so we can do more with leadership later but that's the idea that like the organization start grappling with the questions at the c e o level c suite level of the kinds of things you would talking about here what does our organization do how do you want to look what experiments do you want to do  organizational form like those are fundamental questions and by the way if those aren't answered then the incentives aren't set correctly for people in the organization and everyone in the company wants to know what the like you can't say people work said by say with agents without giving people articulation of what that actuallyl looks like the day today job so that has to have come from the leadership level and one of the bottlenecks by the way has been that sea level people have not used these systems enough and you can see where they do because transformation hap its much more quickly you know mary urdo said j p morgan for examples you know been very public about using ai and that's trickled down and part of why j p morgan does quite well on a i stuff and so there's leadership piece and then there's the crowd that you're talking about everybody gets access these tools in some way or another and then how do you create the incentives so they share what they're doing right because is there's at least like seven or eight reasons why people use a i don't tell you like everyon thinks there genius theyn't want to seem like a genius right now they know that efficiency gains get translateo people being fired they don't want that to happen they're working a lot less and why would they ever return the extra value to the company itself they have come with brilliant ideas that that they don't want to share without you know taking a risk for it like there's lots of reasons people don't share this stuff so you have to align that organization do it and then the issue is like this is done through individual prompting so to turn those into products to turn those into agents to to test where they work or not you need to then extract some of those and start doing some actual real r and d work which doesn't mean this a coding right tool bases like the kinds you build are really important for what you're doing here but it's also just how do we start experimenting how do we take what was a basic prompt and turn into an agent agentic system how do we benchmark that system so you need all three of those pieces at the same time and what use cases have you found over the last year you've done a lot of research both a collaborator sort of assisting consultants and so on what type of use cases do you think are inside of the frontier now where it's delivering a meaningful value so i think it's really clear at this i mean so there's stuff that i think is like c s r people still struggle with right i think that those are in some ways riskier things are extra facing human placement the angle the results are really clear right individuals working with a and especially if you have way people sharing that information ideation it's absolutely useful to have general better ideas work with a right there's some methods that work better than others but that kind of approach for supplementing work of all kinds right translation not just you know translation up and down levels of atraction not just translation directly summarization but where you start to see the really interesting stuff is trying to accelerate cycles so i'm seeing a lot more of like rapid protyping and development so going from like let's take an idea then let's have have the a i let's have the a i generate twenty five ideas let's have a creative rubric and test those ideas then let's put simulated people through those ideas and get their reactions to it refine the ideas further then let's go in and create a you know a prototype working prototype and interview me about how to make it better and then build a vibe coded first version that is literally twenty five minutes of work at this point right with just a command line o three so like we're a very weird spot where it's like but then the organization ends up tripping that up right because what do you do with the fact that now we have forty five great prototypes where's the manufacturing ca ability build it where's the output so that augmentation piece is pretty good at the beginning and then research agents are looking really interesting and then knowledge management agents also seem to have a lot of value right which is like actually this is something you forgot or thought about that where i'm starting to see really interesting stuff happen is advisory like the idea that we're going to give you advice that's timely or and is also really interesting what do you think happens to the economy when we have i mean it's effectively a renaissance where we just have have an abundance of everyone can code everyone can do science everyone can go deep into so many different disciplines if we you know get another sort of ten x output from the medical community as an example will we still be bottlenecked by by by the f  a or do you think the system will will will will adapt and both right systems take a lot longer to change i mean talking the deep mind people and they are saying that there's getting real drug development results in a year that look really good right so they'll be pressure to adapt to those kind of things and i think part of the question like part of the issue with the uncertainty in the regulatory environment whether for different reasons in europe versus the u s for example is is that it makes it hard to figure out where to invest to make these kind of changes happen because we are going there's going to be societal bottlenecks all over the place and there's also you know the i only has limited ability to act in physical world at this point right robotics lags this organizational structure lags this so how do we start thinking about that becomes a really big deal i think part of why people find agents so appealing is in part the idea that they solve some of this problem by just doing stuff so i don't have to worry about it but at some point they're going to hit the real world right and those friction points that is where things slow down on the other hand if you can get up to that friction point and deliver here's seven really good looking you know compounds that might make a difference that is a huge gain anyway so i think that the the gain will be more spread out but we just don't know i mean part of this also is how autonomous the systems get right which roles do you think will will end up being more useful in organizations as a function of this that's a tough one and based a lot of organizational choice right but i think i think management roles does like roles that are sort of think about systems i tend to be very valuable because there's systems are problematic i think experts anywhere become valuable right turns out expertise actually is really good none of these systems are as good as an actual expert at the top of their fields we tend to measure against the average in a field and like the i doeas really well but if you're in the top two percent of something you're going to be beating the e in that field and so expertise actually matters a lot in this space so either deep subject matter expertise broad expertise across many areas as a system leader or really good taste tend to be the three things that help you one thing that i've been thinking a lot about this you know on one end you could be hiring more senior developers asan example where you say you know we just hire the top two percent those are the only folks that are going to you know make a big difference to us another argument could be actually you could hire much more junior developers nowadays because the junior developers would be able to execute the quality of much more senior developers what do you think there should does does the democratization of expertise actually enable you to maye staff here toam with more junior junior talent and maye folks that are slightly more senior will actually not benefit as much from from from this technology so there's actually a few effects happening at once and i think it's more than packing them like ourar bosssult the group study was the first one to document in the real world the idea that like there was this performance gain for the lower performers got the highest gain but people don't talk as much about that why we found out that happened which is we measion call retainment which is how much of theys answers the consults ur ultimately turns their own and for sort of eighty percent of consulting tasks the only way to scrope was to add your own thoughts or ideas andto the eyes answer right as long as you were just turning in the eyes answer you to great as wjeting on thoughts  ideas sos basically working at the eight percent so when you say you're hiring a junior developer in the am makes them better i think it's we're specifying is it just that the human is substituting for the things we can't do agentically yet which is like all pace in the requirement all attend the meeting and the eyes actually doing the work right is or is it actually bringing people up to that level and at the same time at this sort of really good person level we're seeing effects where if you're very good and you use the right way you get ten or a hundred times performance improvement so i think you need to think about both things right there is this sort of substitution effect and my view has been that a lot of the benefit comes from having expertise and then using a i to supplement the areas that you're not you're bad at right like i think about founders all the time a was an entrepreneur i teach entrepreneurship entrepreneurship is all about you being very bad at many things things but really really really good at one thing and your whole task  entrepreneur and the reason why i teach entrepreneurship is to have those you know the ninety five percent of stuff you're bad at not trip you up right like the fact that you didn't know you need a business plan or that you didn't know how to do a pitch like because your idea is brilliant and you know how to execute it in this market and so the fact that i could bring you eighty percent of all of that is a really good thing right and that is replacing your work but in the area where you're at the ninety nine point nine percentle you get one hundred times multiplier and i think that's the same kind of angle and i think the danger is is that if you're hiring junior people expect them to use a the whole time how will they ever become senior becomes a real challenge what do you think the answer to that is like a lot of the law firms i speak to for example this a core part of the training is the you know basic work you do and then as you become more more senior but you do more complex legal analysis but when you look at actually what this juniors are are doing i think most of that work is not actually adding up to what the more senior role will rell be doing it's very simple repetitivet work and so on do you think that will be an issue where people don't grow know through the herarchy to the same extent and as a function of that we don't have as many folks that can step into this more senior roles or will it just go into the sen youor roles more quickly no i'm really worried about that right because like any other university i wharton i know i teach really smart people and but he's be generalous i don't teach them to be you know i teach them about how to do analysis i don't teach them how to be a goldman sachs analyst right but then they go to goldman sachs or they go to a law firm or whatever it is and they learn the same w've been teaching any white collar knowledge work for four thousand years which is apprenticeship right and you're right they're asked to do repetitive work over and over again the repetitive work doing over and over again that's how you learn expertise right you get yelled at by your cmag you're you know at the wrong kind of firm  else treated nicely but you're basically given correction over and over again to you write a deal memo but it's not just that you're learning to write a a deal memo is that you're also learning why this approach didn't work you're absorbing a whole bunch of stuff from your mentor about what the goal of this is so we let like it just happens right apprenticeship if you have a good mentor appriendship is a thing that happens we don't spend a lot of time training people for we just serve it's magic and some people pick it up and then other people get fired right and they might get fired because they're bad but they might get fired because they got unlucky and got a meant good bad mentor or didn't learn the right things that mentorship just snapped the summer that chain that's kept going for a few thousand years because what happens now is if you're a junior person you go to a company you don't want to show people you don't know some things because you want a senior job so you're going to use a i to do everything so you've turned off your brain because the a's better than you and every middle managers realize that rather than going to an intern who sometimes like take messes up or cries you cand just have the a i do the work because it's better than an intern and i really worry about that pipeline being snapped and the problem is is that we've viewed this as an implicit thing like there's very little work in law firms to teach you how to be good at teaching a lawyer right to someone to be a good lawyer instead you hope that you had a good mentor yourself and you replicate what they did right thats why bankers will often you know like a hundred twenty hour weeks is part of your job why because that's always been part of your job and somehow that teaches you something and so i think we have to move much more formally to how do we want to teach people expertise and work on it ironically the one place we do this really well is actually in sports because like that's an area where we've learned how to build expertise right repeated practice with a coach and you know we're going have to do the same kind of thing in other forms of learning as well so how would you think about it if you started a new university now for the intelligence era so assuming you know modls keep get thing better over the next few decades how would you design a university around that so there's a few things happening right one is what should we teach and the other is how should we teach it i'm more concerned about two than one i think there's a big thing of like we need to tach people a i skills and i think as somebody who's worked with these systems a lot you know like there's not that like the skills are first of all l there's like five classes worth of skills to learn right unless you want to build a l m which you shouldn't do it's really like five or six skills classes and then there's a lot of experience and so i think the queste it's less about teaching people to use a i and in fact i think a lot of the discipline stuff that we teach are really important we want people st learn to be good writers we want that broad knowledge right as well as deep knowledge i think universities are well suited to that where we break down is how we teach right and so everybody's cheating right and i deectors don't work and they're alread cheating by the way buto everyon's really cheating and there's a great study that shows that from the beginning of from when the internet erra and social media really kicked in in like two thousand and seven or two thousand and six students at rutgers who did their homework almost all of them did better on tests and by the time you reach twenty twenty almost none of them like twenty percent wearre getting better on tests there cheating right so like you have to do the kind of hard work so a i doesn't let skip the hard work but it will let us with a i tutors on a one to one basis you can actually teach people their level we can help accelerate the learning process in real ways and so i'm much more interested in how you ch and i already did this in my classes how do you transformed how we teach with a i becomes a really interesting question i don't know the subject matter changes and i think we can increase scale also you teach more people but i think that some of the core subjects say the same and you've done some really cool things and we're probably one of the first to actually ask your students to sht what are some other things in which you've deployed this and how you toch everything because one hundred percent i base i mean so i entrepreneurship so the easiest version is it used to be at the end of a class right and you know people have raised hundreds of millions of dollars from my class and ones tum bmy colleagues the same class number but you know you would basically have a business plan and a powerpoint now at the end of a week i have people have working products right like literally when i first introduced chachy bt to my entrepreneurship class the tuesday after it came out you know the ones who was really distracting came to me afterwards said i i just built my entire product while we were talking right and then seemed to tirely novel at the time that you could it would write code was like shocking right and now we're in a very different world for where that is but i think that so i have my students now have a i simulations they play they have to teach the a i something we have a purpose nve i student there's a i mentors for all the class material they have to build cases with a i there's a i watching what they do in in team settings and giving feedback rackings devil's advocate so there's lots of cool ol stuff you can do to supplement it but that's all in service of having a classroom experience that's active and engaged and so i think that classrooms don't go away right but but what we do in them kind of transforms so one thing we've been discussing is the organizational the sign and what it should be structured like should companies hire a si officer who sort of oversees all of the internal deployments should have a model where they deploy someone in each team to figure out the use cases what do you think like would you structure your org so i worry a little bit sometimes in the chief officer thing for the same problem that everybody is having which is everybody wants answers and like i talk to all the air labs a regular base i know you guys do too you've been doing this for much longer than most people in the space and you know the horrible realization you have fairly quite quickly is that nobody knows anything right is not like the labs have an instruction manual out there that they haven't handed to you it's not like there's like more data than what i'm sharing with you guys about this or the share online like there's no secrets right there's like there isn't everyone's like desperate to copy somebody else and there isn't so like when you say hire a chief officer how are they going to have any more experience in the last two years th anyone else did no one thought el m would be this good like you guys were there before almost anyone else that like that gave you a year of head start right like this is a weird place we're in so there isn't someone you can hire who's like the expert and the often i mean one of the major problems of ai in organizations is that i meant something very different from two thousand and ten to twenty twenty two that is still important by the way large data you know going ahead and extraal boosting everything like still worth doing right but like that's a very different beast so a chief a officer is kind of a hard hire i really feel strongly that organizations have the expertise they need to succeed internally because the only people who know how to use ai will be the people who are experts it's very easy for someone who's done a job a thousand times to you know run a model and figure out whether it works or not and in fact in our b c g study we have a second paper that shows that junior people are much worse at using ai than senior people which is not something people think about usually they're like we need the digital generation to come in turns out not to be true because junior people produce a memo and they show that to memo you're like it's a memo it's great and you're like well i've looked at this for twenty i've done this for twenty years here's seven things the memo doesn't do well right so expertise in knowledge matters so i think it's less about embedting people in teams and then we don't even know what makes someone good at ai so what i tend to do is suggest the crowd and lab need to be linked together so what the crowd does is you're not just surfacing you know a i use cases it basically by the way in almost every organization you maxi out it twenty thirty percent of people using your a i model internally and everone else is either not using it or they're cheating and using someone else some of their a i because they want to show you what they're doing but you get like twenty thirty percent of your of your organization using up and then you'll find like one or two percent organization just brilliant of the stuff they're amazing at it those are the people who will be able to lead you in your a i development effort i don't know who they're going to be at first right and you won't know either but they will emerge and then the danger is they're making so much profit for you on the line that you want to pull them off the line but those become the people that be become the center of your lab and figure out how to use it so i really think building internal effort is the right way and it's very hard for me to recommend hiring a bunch of people for a i we don't know what make someone good  the bad a this and your orial context actually matters here and how do you think we set up the incentives so if you have the experts in you really hand its to them to figure out how to deploy and effectively ultimate a with their own role how do you create the right incentives for them to do that and that's why the leadership leg matters so much right so there's a few things you need to do one is this is easier for companies with good culture right if the c e o says growth mode right if the c e o can if you trust the c e o or the founder and they say things like listen we're not going to fire anyone because of a i we're going to expand what we can do we're going to make this work for everybody and people are incentivized to do it you're a much easier spot than if you're a large mature organization that has a tendency to use i t funds to cut people right people will know the difference so you have to acknowledge this to start off with right like if this is going to be a threat to people's jobs people want to know that and you have to start thinking through what you want to say and then incentives can often be pretty crazy in these situations i've talk to one company that gave out ten thousand dollars cash prizes at the end of every week whoever did the best job automating their job and you save money versus typical i deployment just shoving over a suitcase full of cash i've talked to another company that before you hired anyone you needed to show you need to spend two hours a team trying to do the job with a i and then rewrite the job description around the fact that i would be used or you had to spend a few wen youpose a project you had to try using a i to do it and then resubmit the project proposal as a result so like you canentiviz people in lots of different ways but that clarity of vision matters so much right if you say your job in four years will be working with a id something like well what does that mean like my sitting at home you know giving instructions to an agent to my inn a room doing things or the less of us so that vision actually matters and i find way too many executives just want to kick that down the road and say he i will do great stuff why would it ever want to show hre productivity benefits with the organization without being compensated and so starting with that kind of piece is really important so another research you did was when embedded and collaborating like more like a collge and you studied folks that were working individually folks that were working in ms folks that were working individually with folks that were working in tms with with what did that sort of tch us about how this might be embedded into ms so this biggest study with my colleagues in mit and harvard university warwick of seven hundred seventy six people a procor and gamble the big consumer products company and thin you said they were either teams of two cross functional teams or individuals working alone and then work with a i teams are alone first off we found individuals and this is all real job tasks right not just like innovation desks we found that individual working alone with a i performed as well as teams and which was a pretty impressive kind of boost and were actually happier too as a results of working with it like they got some of the social benefits of working with these systems to produce high quality results and we also found that but the teams work with a i were much willing to come through come with really breakthrough ideas we also found that expertise tended to even out so if you sort of mapped how technical solution was and youd technical people in room that reduce highly technical solutions you pretty marketing people produce highly marketing solutions as soon as you added a i the solutions were across the board so they're much more even so it really turned out like this was a good supplement to kind of human work work you know and again this is pretty naive like we gave m a bunch of promps to work with but a lot of it was them just kind of playing with these systems back and forth so you know this leaves the same problem we've had before which is you need to make some decisions like the typical company that sort of sits back and waits for someone else to provide a solution to them is going to be less well off then if you start experimenting now and figure ou what works and what doesn't and what do you think will be the interface for for collaboration wll the just embded into our google docs and our slack and we'll just communicate with them just the way we communicate with with all of our colleagues or do you think there would be something that's more gentative interface where we collaborate with them i mean i think an agent native interface makes a lot more sense you know that born built around teams rather than having each document of a copilot on them i want something to maintain state across the various tasks i mean we're close right like i've got my phone here and i can you know turn on if we want to even do it we could turn on you know agent a look around us and give feedback on what we're doing in the world and i think that that like that's a promising way forward and again it's about that redesigning work i think agendic systems are more interest less interesting almost because they automate work then that they can bring together many threads of work and you mentioned one example a while a while ago which i think it was shoch its like hallucinateed a quote from you and you actually thought that was your your your own your own quote when do you think we'll have the system sscrit you know sort of ethanmlic level research and what's required for that's a just sort of feeding them more of your of your context to do you think we'll get there quite soon then and what will that mean would that mean that you're basically just using your tist to select among the best paper thats generating i mean i think lot of this is already possible with the levels of models we have i mean theres a paper that shows o one preview which is not even a cutting edge model at this point you know the hallucination rate on the new england journal medicine case studies went from like twenty five percent in previous models like point two five percent like the hallucination problem starts to drop when you connected data sources when you have smarter models i mean it's still there but like you mentioned one point that you know i used a in classrooms and my first classroom policy was you could use a in class and that was great for three months right when s be three point five came out my students are smarter than ch p t and it produced much more obvious errors and i let them use ay for anything they wanted because if they don't their own thinking they would get like a b right like i was not capable of doing that g four came out as well as my students you know who aren putting a huge amount of effort in so i think we're in the same kind of boat here which is this iset are very good and as people who build agentic systems i think you're probably realizing what you know we have long realize what i think we know which is a they're capab of a lot more when you start thinking about them agentically and you know google's be doing some stuff of building ai labs there's was a workout of carnegie mellon doing the same sort of stuff i actually think it's more willpower than anything else to build a research system that does interesting work and it's like so many other areas and a i where'm like wow we've already shown that this can work really well as a tutor where are the thousand tutor you know that are actually well done as opposed to just problem the eye to be a tutor where are the thousand science applications where's the internal training systems these are capable right now like it's really just doing it what has been the some of the most surprising things you've gotten to work recently what have you seen in the lit thist generation of the mods things that didn't work previously that now starting to work really well i mean so with the latest versions of say gemini the hardest thing you have to do is an academic is writing what's called tenure statement so you do this hopefully once in your life and you have to write a statement where you go up for tenure and what you have to do is take all the academic work you've done which is often fifteen years of work very complicated and boil it down to a few themes and write an essay sort of about why your research has these themes i was able to recently with the new gemini models dump in all of my academic papers i wrote because the condics one is huge and have a develop those themes and i found two of the three themes i ended up took me two months to write on my own at a fairly high analytical level right like you know or on the more fun version i can now throw in any academic paper ever written and say turn this into a video game and get a good video working video game out of it you know i vib coded some three d games recently which is like i can't code and you know building pretty good working systems so i mean i think like threshold after threshold kind of keeps falling and i'm shot a surprised on a regular basis like can't believe how much these systems could do and how should we be thinking about this in companies is this the equivalent to like deploying more i q into the system is it's deploying more liber into the system or how should i view this as a company so there's a tactical and then there's a philosophic view on the philosophic few we don't really know right like certainly in intelligence but like you you know to knows of labor are just sort of like two very simple inputs right but also what does it mean for better advice to get better advice what's it mean to get better mentor and what's better to have a second opinion right and on the tactical side i think that the thing to aim is be maximalist i think too few organizations are maxals just push this is do everything if it doesn't do it great you had have a benchmark for future systems to test and it might actually just do all the stuff if it does all the stuff you've learned something valuable so i really were with the incrementalist sort of like let's summarize our documents like that's fine but i could do that a long time ago why why you having the documents summarized let's just have a do the thing as opposed to the intermediate step i i think that's a really interesting point because a lot of companies now are like let'smre start with a small proof of concept and then we scale up and then it sort of six months in then they get stuck in that proof of concept and the never quite never quite scale whereas you see others take the approach of let's actually deployed everywhere get everyone access to this and then double down on the use cases that work really well but even that isn't maximist enough you're absolutely right because the problem of the use is the work well as they worked well given the limits of the system and give given what people were able to do at that point and the building apps often the worst kind of angle because you end up with now a semi successful product that you have like that you built around the limitations of lama to two or whatever it is because that was i mean we can talk about prolem on the problems i t teams have with being the nexus of a i deployment is i t is very interested in low latency and low cost right and turns out that low laatedy low costs are the exact opposite of high intelligence in these models so there are times we want to be low lad low cost there's also times where it's like i'm willing to pay fifteen cents sense for a really smart decision or new chemical right like that's a reasonable amount to pay and so you have to like that balancing ac be really hard because people tend to build off a cheap small models and then they get stuck later on right which is why being agnostic is so important but also updating so even when people do this they often don't find the maximus approach so that's where the lab comes and you really need people building impossible things and what's the difference between using it as a sar versus a cyborg and what do you recommend there so so the centur definition is you know gary casprov use that term at first this idea that i kind of took from that was the half person half horse right the idea that like you sa you you're basically dividing up the work with the and i know you know know definition was was bager on that right but like that's how we view this and this is sort of the beginning thing like i hate writing e mails i'm good analysis i'll do the analysis of you e mails cyber work is more blended right so my book is a cyberg task and you know this isn't got a much better since then but at that time it was very writing i'm a very good writer i think or at least i'm proud of my writing so the idea almost no writing but writing books is terrible and so all the things that made writing books terrible it helped me with i got suck a sentence cave me thirty ways to  the sentence and pick one read this chapter and make sure that i'm you know like my substack i have theyes read my substack all the time for two or three of them and give me feedback i rarely you know i use it for core writing but i absolutely get feedback all the time from it and make changes as a result read these academic papers and make sure i'm citing them properly like those those sorts of use cases are where the power really comes it and there was this other study where folks got advice from the ultimately ended up being more productive but it was largely benefiting the more more senior folks and notics much that the lower performers that they couldn't quite sort of internalize that advice what does this mean for advice if everyone is sort of geting you know your advice on how to deploy in their organizations what will that mean for the society so i mean i think part of the thing is it's not always the same advice right like the eys go to context i think the study you talking au is the kenya study of entrepreneurs which is a great controlled study that who only got advice from gd forour they couldn't get to make products for them or anything else and what they found was that for that high performers got i forget was eight or thirteen percent improvement profitability which is by the way insane for advice like if i could do that with my students and just give them advice and get thirty percent probab boost that's amazing and again remember pe people are jagged too so like even if you you're going to need different advice than someone else so you if you get advice from the i it's going to be about the thing you're weakest at not the thing you're strongest at and the low performers did worse because their business were already struggling so they couln implement the ideas so i think it's very much true that the advisory role the second opinion role there's some danger that does shape us all in the same direction right we find this an ideation to the i has a bunch of themes if you work with these models you know that for example like g for loves to generate ideas that have to do with ckrypto it loves to generate ideas that have to do with the r and  b r and it loves environmentally friendly ideas right like just from the way it's post training worked i assume and just churns these out and but we found in some our other work that if you prompt it better you can get as diverse ideas as a group of people so part of this is about like what do is the advisor do for you maybe you wanted four or five advisor you don't want eth theml the advisor or you want me but you also want adam grant and you also want gary kaspar ofv and that can be valuable too and if if i take the kiss ofm abundance here and prompt you to give thirty examples good things companies are to doing deploying it can you list as many as possible how should you amention the example of you know handing out cash for the folks that are deploying it the best what are some of this crazy ideas you've sen i mean only work i have been seeing i mean so there's tons of them i can't give you thirty and i can't even talk about all of them unfortunately because i'm not allowed to but i you know certainly right the easy stuff is all your coders use these you know and but then you know change you reward systems around doing that so every ideation session you stop in the middle of meetings and you ask how it's going so far or whether or not you should continue the meeting at all and then drop out otherwise if the meetings if the i think the meeting is done even in physical meetings just stopping having a conversation with the i and thinking about what they're doing at that stage i have seen cases where people people are using everyone gets a consultant or advisor that they kind of ask about strategy decision making on every point there is really interesting stuff being done on training right so ask the had to simulated training environment to play through that one way or another turns out to be really cool i don't know i'm notle hit thirty here in the room with you but i think probably could absolutely that's how you know i' realize that i'm not doing a very good job and im kind of worried that you do't even respond to to my fblem you have another footage of me that i'm desperately worried this that you're going to get much better answer yeah weill definitely try version will will it will do and and what do you think is the best case scenario so assuming everything gets right this gets deployed into society what do you think is the best case scenario a decade from now i mean so i do think that the idea of sort of let's let's leave aside an a i kind of world where there we're all watchover machines of love and grace right and let's just focus on sort of i think what happens is that you know i mean i the problem is a best case link also requires policy decisions because there is clear going to be employment impact from we don't know what form they're going to take it's very possible that everyone gets more jobs but we need retraining i don't know what the future holds in that case so there has to be some policy piece it's kind of missing on that right now but i think that there is a place where your jobs get more satisfying because you do less grun work where we have a world where productivity is now flowing in fun ways rather than just like prodity office like are you typing enough stuff but like like if you're architecting a system of agents that's building stuff for you suddenly this is feels like a very different kind of world you're in it's much more satisfying right where you work less and more stuff comes out and you add your humaness at the key elements that you know the people who still have a sense of style or approach or perspective produce very different work than somebody else so you have differentiation variation i mean that kind of looks like a world where i gets five to ten times better than does right now but doesn't get beyond that you know which is sort of a weird thing to root for in some ways for that's the easiest way to imagine a you know a kind of outcome that feels like the world of today if the systems get a lot smarter then it's like well why do you come into work when it's like we could sit here and we aut to generate this video here i feel like five years or to come back and recreate the people make it three d put us in a volcano and have us talk individually to everybody in their language and voice right we're close to that so that starts to change job so much more dramatically and what are some believes are in the field currently you really disagree with so i think that there is a huge focus and i understand the safety focus but i think there's a huge focus that we and there's a paper that is proves that that we need to either focus on extential risks or not and i think that there's a lot on extential risk and it's worth thinking about but that worries me a lot less than agency over the decisions we're making right now and i worry that people are by treating ais as technological thing which we're even having this discussion he it's like a steamroller that's not actually how this is right like we have to figure ou how this technology is ed and shaped and that's important and everybody who's at this you know at this event gets to make decisions right about how use in shape and those will in turn shape where i goes so i really worry about this lack of agency kind of approach which is like the i will do things to us we get to make choices and we can make those choices that defend what we think is important to be human what our customers need what society needs and so that concerns me is avoiding that kind of conversation i also think that a lot of people in the technical field of a i don't understand how actual organizations work and that they're messier and that you know even super smart agents won't nesy change ouur companies work overnight right which is why i always struggle five or ten years we don't know when the change happens it will happen in bursts but you know there's a naive a taste sometimes sort of like i have sister who weres a hollywood producer and every time i hear that i will replace hollywood i'm like you don't understand how much work goes into a hollywood film and some of that will disappear in fact they're using a i actually to accelerate performance is one fun example so she is she's made a move movie michelle pfeiffer and every time and when they have to do test audio dubs and they now have a fake michelle feifer voice that they could test the audio dubs with but they never can use that for actual theater crowds because there's good union protections around the actor so it's a test bed to do experiments but michelle feier stills to come in record and her human voice with what she wants to do or not so i think we can build a world where we defend that humanness but we have to make choices to do it and if if you had to prompt a model to ly make all of your decisions from from now on what would you prompt it ok so i probably do something of you know so first of all i'd like to give it a lot of context right something you guys know a lot about about me and my choices so pace a couple couple million characters of stuff but i would probably say you know the good thing i have this advantage disadvantage which is i've written enough that the ayes care about that they have opinions about me and so i get a pretty good act like ethan molloc i get pretty good answers it tends to be a little over enthusiastic and it likes hash tags for some reason that i don't recommend and really love some mojis and i'm not really an a moji person so i think it thinks i more millennial than i am but aside from that if i was asking for be ok so you know taking on the person realizing that you're working for ethan mallock to help make decision in the knowing that you know here are four or five things that he values that are very important and before making a decision i want you to go and pick four or five possible options that we might follow in the decision at least a couple of them should be very radical then i want you to compare those decisions versus each other and give for each one give two or three simulated outcomes then i want you to create a expedient version of ethan and a thoughtful version of eth and have them argue over which appach path is best then i want you give me a set of pros and cons for each of them and then select the best of those so it's a little chain of thought little perspective taking it's a very good very good one we should should try it's one thing i actually i did a couple of years back is a trend one on everything that the jobs had ever said because it was very interesting to get one that was founded in his principle so during covid for example i asked it you know should should we go remote should we become a remote first company and still replied to me no ninety five percent of all communication problems are solved by putting people in the same room always co locate terms and it's quite interesting if you ground it in in a person's writing and so on it gets a specific point of view that's not like the average of the internet yes and that's what's so important when you're going back to the idea of where you get it advice from like and that's why companies are important like your founder can have an influence on this your principles if you give the ai a manual if this is what we believe that will get very different results than someone who isn't i think the idea of reing this is you know universal mind that is always giveing the right answer it's give you o pins of points of view and that is a shapeable thing and if you believe your principles about the world are right giving those principles the i to have it help you execute those principles a lot better than just let it tell you stuff one thing i find quite quite interesting is that this the systems are yet to be optimized for engagement so we basically just tran them to predict the next the next token but if we know anything about this sort of consumer services they'll very soon start evolving to engage us in deeper conversations you can imagine a bot deployed in our organization and we want to maximize the engagement with it and it starts andenticing people and asking them interesting questions and so on what do you think will happen when this once the systems get optimized for for engagement which hasn't really been the case yet yeah i'm nervous about that i think that that is is starting to put fire in the bigger labs are starting to realize they can do that right i think if you kind of look at the trend of open eyes stuff it's become more casual more chatty there's a fun incident where the new lamafore model was just released and it was top of the leaderboards and it was revealed that the version they had there was top of the leaderboards not the same model as the model was releas everybody and if you look at the transcript the leader board one it's full of mojis it tells you how great you are it like makes little jokes that are kind of semi funny and that's not the mall the released right there the's optimized for engagement thing that throws a lot more tokens trying to flatter you and so i do worry about that right we have early evidence that makes things more sticky and that you know that that optimizing for engagement is what made social media such a risky place to be and i really do worry about that kind of outcome and i think it's inevitable thugh and so this is kind of you know what we do with that becomes a really big question and what one thing that i get asked a lot is you know how should we measure the outcome of this so the made a business letter and the they want to measure one thing which showed that do we deployed this senate improved productivity what do you think we should be measuring so i'm going to this is one of my opinions i feel most strongly about which is in the early r and d phase the worst thing do is have a bunch of k p i s right we just talked about maximizing for engagement if you maximize something you'll get the thing you maximize for and probably not the other stuff we don't know what these systems do you're spending r and d cash on this like we know you get performance improvements because we'll see those but if you're optimizing performance is that how many word documents are produced every day is that how fast people turn around their reports like is that what you want to like part of the problemse organizations aren't built for the k p i is that you need to have like people are like it used to be valuable to produce as many words as possible if you can write a good report or four powerpoint presentations or cover six companies now do you want people covering twenty five companies of three hundred power points a week like what it would have maximizing the number of lines of code that people are writing i mean you can imagine some cases how quickly core the clear the backlog is ipportt but is that what we want to people do so i really worr k p is a measurable k p i is being doom especially because they end up always end up falling to cost savings and always thirty percent cost savings and the always let's fire people which countermines everything ing you're doing so i think people do need to adopted an r and d mindset like the protivity canes are pretty clear and will happen pretty quickly and fine throw them into coding because like coding with the clear producivity gains but i really worry about people who's like prodciy gains for document writing feels like a risky thing to do because what are you optimizing for

------------------------------------------------------------
DETAILED SEGMENTS:

 1. [00:00.000 - 00:30.000] (confidence: 0.40)
    you can either fire most of your staff and make more money per barrel of ale or you can beginness and hire hundred thousand people expand worldwide and i really worry about too many people thinking the small path not the big one i would love to start from the very beginning when you were back at mit

 2. [00:30.000 - 01:00.000] (confidence: 0.40)
    with you know the o and marvin minski and so on what were sort of the i b s at abot so this is a little bit of like stolen techno glory because i was not the coder with marvin i was the person in the nm b a program who was trying to help the a i people explain what i was to everybody else i work with marvin and a few other people at the media lab quite a bit on this and it what was really interesting was a lot you know this was sort of during one of the ma various i winters right so it was there was pay

 3. [01:00.000 - 01:30.000] (confidence: 0.40)
    much attention to a i and it was all about sort of elaborate schemes for how we can create intelligence and so there was projects to observe everything a baby did and maybe that would somehow let us make a there was vermentsk society of mind of all these kind of complex interlocking pieces and i think about how kind of ironic it was that the actual solution turn out to be just shove a lot of language into a learning system and you end up with with l m it's interesting because a lot of the technical ideas turned out to

 4. [01:30.000 - 02:00.000] (confidence: 0.40)
    to be incorrect but there was a lot of the core philosophies there that i think are are back in fashion now you had minsky and engelbart engelbart had this philosophy of augmenting human intelligence and minsky was a lot about replacing human intelligence and trying to make machines conscious what were some of those sort of foundational ideas of how it i could be applied than that you think can be relevant now i mean i think that's we're all kind of struggling with right now is now that we

 5. [02:00.000 - 02:30.000] (confidence: 0.40)
    have these things in sight and we know we're back to what is aessenient and what are the t i mean i think was two weeks ago a new paper came out showing that the actual original turning test right gets passed the three party turing test the g b four point five is capable of passing it right and in fact seventy percent the time people will pick the a i as the human in the room which i don't know what that means w it's better than chance but that's interesting and so i think we're faced with all these exact set of issues that a few things are worrying about for a long time so does this

 6. [02:30.000 - 03:00.000] (confidence: 0.40)
    replace humans and what do we use that for right and for augmentation what is augmentation look like becomes the big question right is it you know and we that that debate i think never got as far as as it could be first because this was still kind of fictional right so what do we do with these very intelligent also very limited machines and then where do humans fit into the equation i don't think it was ever answered and now it's only very very important and the churing test was it was a beautiful idea back back then but if we were to design a new

 7. [03:00.000 - 03:30.000] (confidence: 0.40)
    test now a mol test what would be your molic test for g i so i i struggle with a g i a is this concept all the time right which is it's badly defined i mean the reason why turning test is interesting just like all the other test is they were great when we didn't have anything to test right like the turn is great when computers obviously failed it similarly have issues where the acing all the creativity tests we have but those were designed and they were always mediocre for humans and now we're expecting i to do them the way we figure out whether someone has empathy in social science is the

 8. [03:30.000 - 04:00.000] (confidence: 0.40)
    the best test is of the called the reading the mind in the eyes test we show a bunch of eyes and ask what emotion they have like none of these things were designed for a i stuff so i think about this a lot and i'm ten be very practically oriented on this right so firs a everyone kind of has their own a g i s test you know i'm a business school professor some with some of the easiest is can this agent go in the world and make money and do things is a useful useful test can we discover new knowledge and actually test and come with results but i mean i think what we're starting to realize is a

 9. [04:00.000 - 04:30.000] (confidence: 0.40)
    a g i is going to be this sort of phase we're in rather thn a moment in time right there's not going to be a you know fireworks going off tyler cohen just said three is a g i and when asked why he says it's like pornography i know when i see it and so we don't know what the answer to these questions are and i think it's kind of realizing the meaninglessness of it because it turns out also like as you guys have learned if you connect a i to systems in the right way and you connect the company processes sden you have something that's much better in the sum of its parts  something you're prompting you're just doing conversation

10. [04:30.000 - 05:00.000] (confidence: 0.40)
    and that's feels very different then can we do stret strateic decision making for example and frequently when this models are realist it's always on the most hardcore math problems and science problems it's it's very rarely the take more business applications if you were to decide sign a benchmark that was more focused on the applications that you see in companies what would a benchmark for that look like so i think that is one of the most critical problems we're facing right now because all of the people in the labs

11. [05:00.000 - 05:30.000] (confidence: 0.40)
    are math and science people and they view the only good thing you could do with your life is coding right and then add to that the fact that they want to use ai to make better a i and coding and math becomes like the important things followed by biology because they all want to live forever so like that becomes the angle that that this goes down and there are very few benchmarks other things so we know the ice companies build towards benchmarks a bll sketchy ways right of like optimizing for benchmarks but also in more broad ways of they use this for testing and so the fact the lack of good business benchmarks is a real problem so i

12. [05:30.000 - 06:00.000] (confidence: 0.40)
    i actually one thing i've been pushing is companies should be doing this themselves to some extent right like and some of this could be direct number based like how often does it mess up in being asked to do an accounting process but some of this is bvibes based as they say it would you actually could have outside experts we've done this for somemmer experiments judge the quality of answers and is this is good as a human or not have your own turning tests for various important parts of your job right is the analysis report good enough what's the error rate on it you know if we use this to give us to give a strategy advice how good is it how good is it a selection decision

13. [06:00.000 - 06:30.000] (confidence: 0.40)
    and those are questions are not that hard to measure right they're not that technical but they do require a little bit of effort i think that's that's one of the areas where products have been largely lacking too especially when you deploy agents the ability to test a agents and see what knowledge they have and what knowledge they're lacking and correct them and run this test sets has been really really limit limited so as we think about de signing and first org so you basically get a thousand

14. [06:30.000 - 07:00.000] (confidence: 0.40)
    in person company and you gets to real design that work to be completely how do you structure it so the first thing you say is redesigned to be i native is hard because it was 'an a i native right so we are we are in this really interesting spot where we've had basically hundreds of years of organizational development that is paralleled you know in es revolution the communication revolution i mean the first or chart came out in eight hundred fifty five for the ne in railroad and it solved a problem that never existed before which is how do we coordinate

15. [07:00.000 - 07:30.000] (confidence: 0.40)
    coordinate vast amounts of you know traffic on train lines in real time using a telegraph and they came up ckenzie the guy who came up with this came up with the or chart as a solution we still use them todayine hdd ten huge breakthroughs in organizing work henry ford's production lines time clocks still use those today early two thousand agile development right all of these things broke because they all depended on there being only one form of intelligence available which is human comes in human sized packages can only be deployed with a span of control of five or seven people you know

16. [07:30.000 - 08:00.000] (confidence: 0.40)
    two pizza problem and now we're in a world where that isn't the case so things have to be rebuilt from the ground up and i worry a little bit that modern western companies have given up an organizational innovation a something they do it used to be that the way dow chemical would win or the way that i b m would win would they' come with new approaches to sales or new approaches to work with organizations and now we've outsourced that so enterprise software companies will tell you how to build your company because sales force sells you a sales force product that tes you how you sales or a large scale consul the company will come

17. [08:00.000 - 08:30.000] (confidence: 0.40)
    come in and tell you how how your organization should run and now is a time where leaders actually need to innovate so if to return to your sort of core question it has to be building from both the idea that we're heading in in a trend line where humans are less necessary in the product and then where do you get you have to pick your whether you augmentation replacement and then you have to start building the systems from that fewer people doing more impressive work or more people doing ever more work and trying to take over the world together the this that we have

18. [08:30.000 - 09:00.000] (confidence: 0.40)
    have sort of fewer hundred x employees or do we sort of boost double the productivity of everyone do do create this sort of small clusters of folks that are overseeing the orchestration of agents and are you know orders of magnitude more more more productive or is it sort of more deployed horizontally across the organization where a few people get more more so i think those are hey choices i mean one of things i really worry about is when i look at early implementations what people

19. [09:00.000 - 09:30.000] (confidence: 0.40)
    view this is as an efficiency technology and i bear a little blame for that our earliert work focus on productivity gains from a i and i still focus on that because i matters but i worry a lot that at the edge of industrial revolution what we're seeing happen or some sort of new revolution what we're seeing happen right now is that companies are viewing this like a normal technology so they get a twenty five percent cost savings from you know or efficiency gain in customer service let's cut twenty five percent of people right like i hear that all the time and there's a whole bunch of dangers with that one of them is

20. [09:30.000 - 10:00.000] (confidence: 0.40)
    nobody knows how to deploy a i in your organization other than you right you can build tools and the techniques that are really useful but ultimately it has to people in the company that figure out is this good or bad they're the ones with the experience the evidence to do it if they're terrified of doing that because they'll get fired or punished for using ai or they'll be replaced beuse if there's efficiency gain they'll never show youun efficiency gain right and then the second set of problems around that is if we're really in a world we're about to see an explosion of performance of productivity the idea that you should be as small mean as possible going into that like it's like if you imagine

21. [10:00.000 - 10:30.000] (confidence: 0.40)
    in the early industrial revolution and you are you're a you know a local brewer in the early eight hundreds you get steam power you can either fire most of your staff make more money per barrel of ale or you beginness and hire on hundred thousand people expand worldwide and i really worry about too many people thinking the small path not the big one and you've generally advocated more for human augment and the idea that you know the back ino days weused to talk about bicycles for the mine and now we might be getting you know airplanes for the mine

22. [10:30.000 - 11:00.000] (confidence: 0.40)
    to some extent in what ways do you think this will be augmenting human human intelligence what because it's been quite counterintuitive what we thought historically was it would start with themn then repetitive tasks and then it would move on to knowledge work en coding and then the very last thing you would take would be the creative tasks but it's almost been like the exact opposite in the sense that you know the creative tasks the knowledge work but the

23. [11:00.000 - 11:30.000] (confidence: 0.40)
    then repetitive has been really tricky to ultimate so in what ways do you think we'll actually be implementing this i mean it is fascinating how much like everywhere you know the image of a i would be that if you taught if you tried to explain the concept love it would explode right does not compute instead we have these weird systems that are super emotional and have to be convinced to do things right like we've actually found imprompt engineering sometimes that what you have to do is actually just justify the i why it should do a step rather tell you do something like that this is why it's supported you should do it which

24. [11:30.000 - 12:00.000] (confidence: 0.40)
    which is super weird and so the thing to think about with augment though is that our jobs are that we do are bundles of many different tasks right nobody would have designed any job that we have i as a professor right when is to was to a good teacher and come with good ideas to be able to have a conversation with you and do research and run an academic department and you know like the one would e be a counselor right no one want all of these jobs and a lot of them are sort of hot as jobs i don't mind giving away grading to an

25. [12:00.000 - 12:30.000] (confidence: 0.40)
    a i right if that helps like i wouldn't mind providing more counseling support through a i if that helps even though they're very human kinds of things so i don't think that augmentation necessarily mean like just because it does creative engaging sort of human knowledge work tasks at least at the current levels were at it's definitely below the expert level in these kind of cases whever you're best st you're probably better than a i so the question become augmentation level one is just handoff stuff you're less good at as part of your job bundle and the second level is how do to use it to boost what you're doing right now and we're starying to get some good evidence

26. [12:30.000 - 13:00.000] (confidence: 0.40)
    for that too and what happens when the systems become more proactive than than really active we're so reliant on giving this systems input to what this should give back to us and prompting them and so on at some point we should be getting systems that are better than us at asking those questions too and can sort of proactively serve this to us is that something you're saying if you take your dom

27. [13:00.000 - 13:30.000] (confidence: 0.40)
    an examplef could go out and do all of the research for you and then come and sa sort of this this matches your research tt here are five papers i wrote pick the best one have you started seeing any applications like that yeah i mean there's a couple things you said there that are really important one of them is actually the more minor point which is the idea that it gives me ten papers to pick from right this idea of you know it ho we're now but abundance but we're not used to a situation where you can just get a lot of something and cure

28. [13:30.000 - 14:00.000] (confidence: 0.40)
    curate right so one of the things that actually matters a lot is taste and curation that i want to be able to pick out of a subset of options andn that still matters a lot that kind of taste piece or what to pursue and i startt management which is not the end of the world right like management is what most of us aspire to anyway right or at least a lot of people aspire to and it starts to be giving your direction taste where it goes but like i think at the end of this we don't know how good the systems get and that ultimately every question becomes downstream of how good you think i gets right if it's

29. [14:00.000 - 14:30.000] (confidence: 0.40)
    it's good enough that it does all of our work at the high level of what the work you do in your organization does the work that i do as a professor then you know we're sort of inan uncharted territory overall and i don't know what the answer is i think that real organizations are you know work much more in much more complex ways than we think about th i always aim for efficiency and i remains very jagged in its frontier of capability so it can't quite do the whole paper because parts of it all fail but i if i have experience i'll know where those fail and can intervene and shape those

30. [14:30.000 - 15:00.000] (confidence: 0.40)
    places just like i would with a ph d student so i think we're going to be a longer world of limit autonomy than people think where like direction guidance you know is still going to be important i think the jaged from tars is probably one of the areas that's most bot the lking organizations now it's so incredibly confusing talking to a system that sometimes is genius and sometimes it's completely stupid and it also makes it very difficult to deploy it on the dead in the organization

31. [15:00.000 - 15:30.000] (confidence: 0.40)
    a bit similarly we've had with self driving cars where the deployment took a very long time because it was both sort of superhuman in some applications and other in other situations get quite tripped up what do you think will will s in unided agents andw how they will be deployed wll will be you know bottlenecked for another decade by the jagged frontier or will we start trusting these systems and to d quite soon i mean i think we're already a place where narrow agents are very good right

32. [15:30.000 - 16:00.000] (confidence: 0.40)
    so the best example those are the deep research agents that now been rolled out by you know google open e and x right and their perplexi as well the they're all very good right and they do the narrow task of finding information being you know giving you answers very well and that is a highly remunerated task right and they're not quite there yet because they don't have access the kind of private data that people need to be able to use these systems fully but you know the' starting to get very good legal research accounting and market research and finance research and like so i think that they'll

33. [16:00.000 - 16:30.000] (confidence: 0.40)
    that kind of delegation to a fairly complex taest and narrow agents feels very doable i think there are clever ways to generalize agents with other agents watching them that no one's really pushing yet like we were so new into this that the that youre kind of have to make two bets right one is the whole of frintier when w i came with the idea of jagged front heer is like the frontier is constantly pushing out so it's jagged right some of those jgonis will stick around for a while some it doesn't matter if it's still bad at it because it's as the ays get better overall it's

34. [16:30.000 - 17:00.000] (confidence: 0.40)
    it still beats humans right and so i think part of this is the question do you wait for the frontier to move out and then solve the problems or do you build around them today and i think part of the key is doing both right of like how do we but if you invest too much on trying to solve the jagonist today as long as models keep getting better you end up stuck with a legacy system built around a jagged frontier that no longer exists makes makes a lot of sense and one thing that's organizations find it quite tricky is discovering that

35. [17:00.000 - 17:30.000] (confidence: 0.40)
    use cases and have some bottoms up strateges where effectively most parts of the organizations is already using this tools to some extent but just not telling their their leadership and then they have some top down initiatives where they're like let's build some i sd r sor whatever that that might be how would you approach you know discovering these use cases internally what are some tactics there so i tend to say you need three things to make a i work in  organization you need leadership

36. [17:30.000 - 18:00.000] (confidence: 0.40)
    lab and crowd so we can do more with leadership later but that's the idea that like the organization start grappling with the questions at the c e o level c suite level of the kinds of things you would talking about here what does our organization do how do you want to look what experiments do you want to do  organizational form like those are fundamental questions and by the way if those aren't answered then the incentives aren't set correctly for people in the organization and everyone in the company wants to know what the like you can't say people work said by say with agents without giving people articulation of what that actuallyl

37. [18:00.000 - 18:30.000] (confidence: 0.40)
    looks like the day today job so that has to have come from the leadership level and one of the bottlenecks by the way has been that sea level people have not used these systems enough and you can see where they do because transformation hap its much more quickly you know mary urdo said j p morgan for examples you know been very public about using ai and that's trickled down and part of why j p morgan does quite well on a i stuff and so there's leadership piece and then there's the crowd that you're talking about everybody gets access these tools in some way or another and then how do you create the incentives so they share what they're doing right because

38. [18:30.000 - 19:00.000] (confidence: 0.40)
    is there's at least like seven or eight reasons why people use a i don't tell you like everyon thinks there genius theyn't want to seem like a genius right now they know that efficiency gains get translateo people being fired they don't want that to happen they're working a lot less and why would they ever return the extra value to the company itself they have come with brilliant ideas that that they don't want to share without you know taking a risk for it like there's lots of reasons people don't share this stuff so you have to align that organization do it and then the issue is like this is done through individual prompting so to turn those into products to turn those into agents to

39. [19:00.000 - 19:30.000] (confidence: 0.40)
    to test where they work or not you need to then extract some of those and start doing some actual real r and d work which doesn't mean this a coding right tool bases like the kinds you build are really important for what you're doing here but it's also just how do we start experimenting how do we take what was a basic prompt and turn into an agent agentic system how do we benchmark that system so you need all three of those pieces at the same time and what use cases have you found over the last year you've done a lot of research both a collaborator

40. [19:30.000 - 20:00.000] (confidence: 0.40)
    sort of assisting consultants and so on what type of use cases do you think are inside of the frontier now where it's delivering a meaningful value so i think it's really clear at this i mean so there's stuff that i think is like c s r people still struggle with right i think that those are in some ways riskier things are extra facing human placement the angle the results are really clear right individuals working with a and especially if you have way people

41. [20:00.000 - 20:30.000] (confidence: 0.40)
    sharing that information ideation it's absolutely useful to have general better ideas work with a right there's some methods that work better than others but that kind of approach for supplementing work of all kinds right translation not just you know translation up and down levels of atraction not just translation directly summarization but where you start to see the really interesting stuff is trying to accelerate cycles so i'm seeing a lot more of like rapid protyping and development so going from like let's take an idea then let's have

42. [20:30.000 - 21:00.000] (confidence: 0.40)
    have the a i let's have the a i generate twenty five ideas let's have a creative rubric and test those ideas then let's put simulated people through those ideas and get their reactions to it refine the ideas further then let's go in and create a you know a prototype working prototype and interview me about how to make it better and then build a vibe coded first version that is literally twenty five minutes of work at this point right with just a command line o three so like we're a very weird spot where it's like but then the organization ends up tripping that up right because what do you do with the fact that now we have

43. [21:00.000 - 21:30.000] (confidence: 0.40)
    forty five great prototypes where's the manufacturing ca ability build it where's the output so that augmentation piece is pretty good at the beginning and then research agents are looking really interesting and then knowledge management agents also seem to have a lot of value right which is like actually this is something you forgot or thought about that where i'm starting to see really interesting stuff happen is advisory like the idea that we're going to give you advice that's timely or and is also really interesting what do you think happens to the economy when we have i mean it's effectively a renaissance where we just have

44. [21:30.000 - 22:00.000] (confidence: 0.40)
    have an abundance of everyone can code everyone can do science everyone can go deep into so many different disciplines if we you know get another sort of ten x output from the medical community as an example will we still be bottlenecked by by by the f  a or do you think the system will will will will adapt and both right systems take a lot longer to change i mean

45. [22:00.000 - 22:30.000] (confidence: 0.40)
    talking the deep mind people and they are saying that there's getting real drug development results in a year that look really good right so they'll be pressure to adapt to those kind of things and i think part of the question like part of the issue with the uncertainty in the regulatory environment whether for different reasons in europe versus the u s for example is is that it makes it hard to figure out where to invest to make these kind of changes happen because we are going there's going to be societal bottlenecks all over the place and there's also you know the i only has limited ability to act in physical

46. [22:30.000 - 23:00.000] (confidence: 0.40)
    world at this point right robotics lags this organizational structure lags this so how do we start thinking about that becomes a really big deal i think part of why people find agents so appealing is in part the idea that they solve some of this problem by just doing stuff so i don't have to worry about it but at some point they're going to hit the real world right and those friction points that is where things slow down on the other hand if you can get up to that friction point and deliver here's seven really good looking you know compounds that might make a difference that is a huge gain anyway so i think that the

47. [23:00.000 - 23:30.000] (confidence: 0.40)
    the gain will be more spread out but we just don't know i mean part of this also is how autonomous the systems get right which roles do you think will will end up being more useful in organizations as a function of this that's a tough one and based a lot of organizational choice right but i think i think management roles does like roles that are sort of think about systems i tend to be very valuable because there's systems are problematic i think experts anywhere become valuable right

48. [23:30.000 - 24:00.000] (confidence: 0.40)
    turns out expertise actually is really good none of these systems are as good as an actual expert at the top of their fields we tend to measure against the average in a field and like the i doeas really well but if you're in the top two percent of something you're going to be beating the e in that field and so expertise actually matters a lot in this space so either deep subject matter expertise broad expertise across many areas as a system leader or really good taste tend to be the three things that help you one thing that i've been thinking a lot about this you know

49. [24:00.000 - 24:30.000] (confidence: 0.40)
    on one end you could be hiring more senior developers asan example where you say you know we just hire the top two percent those are the only folks that are going to you know make a big difference to us another argument could be actually you could hire much more junior developers nowadays because the junior developers would be able to execute the quality of much more senior developers what do you think there should does does the democratization of expertise actually enable you to

50. [24:30.000 - 25:00.000] (confidence: 0.40)
    maye staff here toam with more junior junior talent and maye folks that are slightly more senior will actually not benefit as much from from from this technology so there's actually a few effects happening at once and i think it's more than packing them like ourar bosssult the group study was the first one to document in the real world the idea that like there was this performance gain for the lower performers got the highest gain but people don't talk as much about that why we found out that happened which is we measion call retainment which is how much of theys answers the consults

51. [25:00.000 - 25:30.000] (confidence: 0.40)
    ur ultimately turns their own and for sort of eighty percent of consulting tasks the only way to scrope was to add your own thoughts or ideas andto the eyes answer right as long as you were just turning in the eyes answer you to great as wjeting on thoughts  ideas sos basically working at the eight percent so when you say you're hiring a junior developer in the am makes them better i think it's we're specifying is it just that the human is substituting for the things we can't do agentically yet which is like all pace in the requirement all attend the meeting and the eyes actually doing the work right is or is it actually bringing people up to that level

52. [25:30.000 - 26:00.000] (confidence: 0.40)
    and at the same time at this sort of really good person level we're seeing effects where if you're very good and you use the right way you get ten or a hundred times performance improvement so i think you need to think about both things right there is this sort of substitution effect and my view has been that a lot of the benefit comes from having expertise and then using a i to supplement the areas that you're not you're bad at right like i think about founders all the time a was an entrepreneur i teach entrepreneurship entrepreneurship is all about you being very bad at many things

53. [26:00.000 - 26:30.000] (confidence: 0.40)
    things but really really really good at one thing and your whole task  entrepreneur and the reason why i teach entrepreneurship is to have those you know the ninety five percent of stuff you're bad at not trip you up right like the fact that you didn't know you need a business plan or that you didn't know how to do a pitch like because your idea is brilliant and you know how to execute it in this market and so the fact that i could bring you eighty percent of all of that is a really good thing right and that is replacing your work but in the area where you're at the ninety nine point nine percentle you get one hundred times multiplier and i think that's the same kind of

54. [26:30.000 - 27:00.000] (confidence: 0.40)
    angle and i think the danger is is that if you're hiring junior people expect them to use a the whole time how will they ever become senior becomes a real challenge what do you think the answer to that is like a lot of the law firms i speak to for example this a core part of the training is the you know basic work you do and then as you become more more senior but you do more complex legal analysis but when you look at actually what this juniors are are doing i think most of that work is not actually adding

55. [27:00.000 - 27:30.000] (confidence: 0.40)
    up to what the more senior role will rell be doing it's very simple repetitivet work and so on do you think that will be an issue where people don't grow know through the herarchy to the same extent and as a function of that we don't have as many folks that can step into this more senior roles or will it just go into the sen youor roles more quickly no i'm really worried about that right because like any other university i wharton i know i teach really smart people and but he's be generalous

56. [27:30.000 - 28:00.000] (confidence: 0.40)
    i don't teach them to be you know i teach them about how to do analysis i don't teach them how to be a goldman sachs analyst right but then they go to goldman sachs or they go to a law firm or whatever it is and they learn the same w've been teaching any white collar knowledge work for four thousand years which is apprenticeship right and you're right they're asked to do repetitive work over and over again the repetitive work doing over and over again that's how you learn expertise right you get yelled at by your cmag you're you know at the wrong kind of firm  else treated nicely but you're basically given correction over and over again to you write a deal memo but it's not just that you're learning to write a

57. [28:00.000 - 28:30.000] (confidence: 0.40)
    a deal memo is that you're also learning why this approach didn't work you're absorbing a whole bunch of stuff from your mentor about what the goal of this is so we let like it just happens right apprenticeship if you have a good mentor appriendship is a thing that happens we don't spend a lot of time training people for we just serve it's magic and some people pick it up and then other people get fired right and they might get fired because they're bad but they might get fired because they got unlucky and got a meant good bad mentor or didn't learn the right things that mentorship just snapped the summer that chain that's kept going for a few thousand years because

58. [28:30.000 - 29:00.000] (confidence: 0.40)
    what happens now is if you're a junior person you go to a company you don't want to show people you don't know some things because you want a senior job so you're going to use a i to do everything so you've turned off your brain because the a's better than you and every middle managers realize that rather than going to an intern who sometimes like take messes up or cries you cand just have the a i do the work because it's better than an intern and i really worry about that pipeline being snapped and the problem is is that we've viewed this as an implicit thing like there's very little work in law firms to teach you how to be good at teaching a lawyer right

59. [29:00.000 - 29:30.000] (confidence: 0.40)
    to someone to be a good lawyer instead you hope that you had a good mentor yourself and you replicate what they did right thats why bankers will often you know like a hundred twenty hour weeks is part of your job why because that's always been part of your job and somehow that teaches you something and so i think we have to move much more formally to how do we want to teach people expertise and work on it ironically the one place we do this really well is actually in sports because like that's an area where we've learned how to build expertise right repeated practice with a coach and you know we're going have to do the same kind of thing in other forms of learning as well

60. [29:30.000 - 30:00.000] (confidence: 0.40)
    so how would you think about it if you started a new university now for the intelligence era so assuming you know modls keep get thing better over the next few decades how would you design a university around that so there's a few things happening right one is what should we teach and the other is how should we teach it i'm more concerned about two than one i think there's a big thing of like we need to tach people a i skills and i think as somebody who's worked with these systems a lot you know like there's not that like the skills are first of all

61. [30:00.000 - 30:30.000] (confidence: 0.40)
    l there's like five classes worth of skills to learn right unless you want to build a l m which you shouldn't do it's really like five or six skills classes and then there's a lot of experience and so i think the queste it's less about teaching people to use a i and in fact i think a lot of the discipline stuff that we teach are really important we want people st learn to be good writers we want that broad knowledge right as well as deep knowledge i think universities are well suited to that where we break down is how we teach right and so everybody's cheating right and i deectors don't work and they're alread

62. [30:30.000 - 31:00.000] (confidence: 0.40)
    cheating by the way buto everyon's really cheating and there's a great study that shows that from the beginning of from when the internet erra and social media really kicked in in like two thousand and seven or two thousand and six students at rutgers who did their homework almost all of them did better on tests and by the time you reach twenty twenty almost none of them like twenty percent wearre getting better on tests there cheating right so like you have to do the kind of hard work so a i doesn't let skip the hard work but it will let us with a i tutors on a one to one basis you can actually teach people

63. [31:00.000 - 31:30.000] (confidence: 0.40)
    their level we can help accelerate the learning process in real ways and so i'm much more interested in how you ch and i already did this in my classes how do you transformed how we teach with a i becomes a really interesting question i don't know the subject matter changes and i think we can increase scale also you teach more people but i think that some of the core subjects say the same and you've done some really cool things and we're probably one of the first to actually ask your students to sht what are some other things in which you've deployed this and how you

64. [31:30.000 - 32:00.000] (confidence: 0.40)
    toch everything because one hundred percent i base i mean so i entrepreneurship so the easiest version is it used to be at the end of a class right and you know people have raised hundreds of millions of dollars from my class and ones tum bmy colleagues the same class number but you know you would basically have a business plan and a powerpoint now at the end of a week i have people have working products right like literally when i first introduced chachy bt to my entrepreneurship class the tuesday after it came out you know the ones who was really distracting came to me afterwards said i

65. [32:00.000 - 32:30.000] (confidence: 0.40)
    i just built my entire product while we were talking right and then seemed to tirely novel at the time that you could it would write code was like shocking right and now we're in a very different world for where that is but i think that so i have my students now have a i simulations they play they have to teach the a i something we have a purpose nve i student there's a i mentors for all the class material they have to build cases with a i there's a i watching what they do in in team settings and giving feedback rackings devil's advocate so there's lots of cool

66. [32:30.000 - 33:00.000] (confidence: 0.40)
    ol stuff you can do to supplement it but that's all in service of having a classroom experience that's active and engaged and so i think that classrooms don't go away right but but what we do in them kind of transforms so one thing we've been discussing is the organizational the sign and what it should be structured like should companies hire a si officer who sort of oversees all of the internal deployments should have a model where they deploy someone in each team to figure out the use cases

67. [33:00.000 - 33:30.000] (confidence: 0.40)
    what do you think like would you structure your org so i worry a little bit sometimes in the chief officer thing for the same problem that everybody is having which is everybody wants answers and like i talk to all the air labs a regular base i know you guys do too you've been doing this for much longer than most people in the space and you know the horrible realization you have fairly quite quickly is that nobody knows anything right is not like the labs have an instruction manual out there that they haven't handed to you it's not like there's like more data than what i'm sharing with you guys about this or the share online like there's no secrets right there's like

68. [33:30.000 - 34:00.000] (confidence: 0.40)
    there isn't everyone's like desperate to copy somebody else and there isn't so like when you say hire a chief officer how are they going to have any more experience in the last two years th anyone else did no one thought el m would be this good like you guys were there before almost anyone else that like that gave you a year of head start right like this is a weird place we're in so there isn't someone you can hire who's like the expert and the often i mean one of the major problems of ai in organizations is that i meant something very different from two thousand and ten to twenty twenty two that is still important by the way large data you know going ahead

69. [34:00.000 - 34:30.000] (confidence: 0.40)
    and extraal boosting everything like still worth doing right but like that's a very different beast so a chief a officer is kind of a hard hire i really feel strongly that organizations have the expertise they need to succeed internally because the only people who know how to use ai will be the people who are experts it's very easy for someone who's done a job a thousand times to you know run a model and figure out whether it works or not and in fact in our b c g study we have a second paper that shows that junior people are much worse at using ai than senior people which is not something people think about usually they're like we need the digital generation to come in

70. [34:30.000 - 35:00.000] (confidence: 0.40)
    turns out not to be true because junior people produce a memo and they show that to memo you're like it's a memo it's great and you're like well i've looked at this for twenty i've done this for twenty years here's seven things the memo doesn't do well right so expertise in knowledge matters so i think it's less about embedting people in teams and then we don't even know what makes someone good at ai so what i tend to do is suggest the crowd and lab need to be linked together so what the crowd does is you're not just surfacing you know a i use cases it basically by the way in almost every organization you maxi out it twenty thirty percent of people using your

71. [35:00.000 - 35:30.000] (confidence: 0.40)
    a i model internally and everone else is either not using it or they're cheating and using someone else some of their a i because they want to show you what they're doing but you get like twenty thirty percent of your of your organization using up and then you'll find like one or two percent organization just brilliant of the stuff they're amazing at it those are the people who will be able to lead you in your a i development effort i don't know who they're going to be at first right and you won't know either but they will emerge and then the danger is they're making so much profit for you on the line that you want to pull them off the line but those become the people that be

72. [35:30.000 - 36:00.000] (confidence: 0.40)
    become the center of your lab and figure out how to use it so i really think building internal effort is the right way and it's very hard for me to recommend hiring a bunch of people for a i we don't know what make someone good  the bad a this and your orial context actually matters here and how do you think we set up the incentives so if you have the experts in you really hand its to them to figure out how to deploy and effectively ultimate a with their own role how do you create the right incentives for them to do that

73. [36:00.000 - 36:30.000] (confidence: 0.40)
    and that's why the leadership leg matters so much right so there's a few things you need to do one is this is easier for companies with good culture right if the c e o says growth mode right if the c e o can if you trust the c e o or the founder and they say things like listen we're not going to fire anyone because of a i we're going to expand what we can do we're going to make this work for everybody and people are incentivized to do it you're a much easier spot than if you're a large mature organization that has a tendency to use i t funds to cut people right people will know the difference so you have to acknowledge this to start off with right like if this is going to be

74. [36:30.000 - 37:00.000] (confidence: 0.40)
    a threat to people's jobs people want to know that and you have to start thinking through what you want to say and then incentives can often be pretty crazy in these situations i've talk to one company that gave out ten thousand dollars cash prizes at the end of every week whoever did the best job automating their job and you save money versus typical i deployment just shoving over a suitcase full of cash i've talked to another company that before you hired anyone you needed to show you need to spend two hours a team trying to do the job with a i and then rewrite the job description around the fact that i would be used or you had to

75. [37:00.000 - 37:30.000] (confidence: 0.40)
    spend a few wen youpose a project you had to try using a i to do it and then resubmit the project proposal as a result so like you canentiviz people in lots of different ways but that clarity of vision matters so much right if you say your job in four years will be working with a id something like well what does that mean like my sitting at home you know giving instructions to an agent to my inn a room doing things or the less of us so that vision actually matters and i find way too many executives just want to kick that down the road and say he i will do great stuff why would it ever want to show

76. [37:30.000 - 38:00.000] (confidence: 0.40)
    hre productivity benefits with the organization without being compensated and so starting with that kind of piece is really important so another research you did was when embedded and collaborating like more like a collge and you studied folks that were working individually folks that were working in ms folks that were working individually with folks that were working in tms with with what did that sort of tch us about how this might be embedded into ms so this biggest study with my colleagues in mit and harvard

77. [38:00.000 - 38:30.000] (confidence: 0.40)
    university warwick of seven hundred seventy six people a procor and gamble the big consumer products company and thin you said they were either teams of two cross functional teams or individuals working alone and then work with a i teams are alone first off we found individuals and this is all real job tasks right not just like innovation desks we found that individual working alone with a i performed as well as teams and which was a pretty impressive kind of boost and were actually happier too as a results of working with it like they got some of the social

78. [38:30.000 - 39:00.000] (confidence: 0.40)
    benefits of working with these systems to produce high quality results and we also found that but the teams work with a i were much willing to come through come with really breakthrough ideas we also found that expertise tended to even out so if you sort of mapped how technical solution was and youd technical people in room that reduce highly technical solutions you pretty marketing people produce highly marketing solutions as soon as you added a i the solutions were across the board so they're much more even so it really turned out like this was a good supplement to kind of human work

79. [39:00.000 - 39:30.000] (confidence: 0.40)
    work you know and again this is pretty naive like we gave m a bunch of promps to work with but a lot of it was them just kind of playing with these systems back and forth so you know this leaves the same problem we've had before which is you need to make some decisions like the typical company that sort of sits back and waits for someone else to provide a solution to them is going to be less well off then if you start experimenting now and figure ou what works and what doesn't and what do you think will be the interface for for collaboration wll the just embded

80. [39:30.000 - 40:00.000] (confidence: 0.40)
    into our google docs and our slack and we'll just communicate with them just the way we communicate with with all of our colleagues or do you think there would be something that's more gentative interface where we collaborate with them i mean i think an agent native interface makes a lot more sense you know that born built around teams rather than having each document of a copilot on them i want something to maintain state across the various tasks i mean we're close right like i've got my phone here and i can you know turn on

81. [40:00.000 - 40:30.000] (confidence: 0.40)
    if we want to even do it we could turn on you know agent a look around us and give feedback on what we're doing in the world and i think that that like that's a promising way forward and again it's about that redesigning work i think agendic systems are more interest less interesting almost because they automate work then that they can bring together many threads of work and you mentioned one example a while a while ago which i think it was shoch its like hallucinateed a quote from you and you actually thought that was your your

82. [40:30.000 - 41:00.000] (confidence: 0.40)
    your own your own quote when do you think we'll have the system sscrit you know sort of ethanmlic level research and what's required for that's a just sort of feeding them more of your of your context to do you think we'll get there quite soon then and what will that mean would that mean that you're basically just using your tist to select among the best paper thats generating i mean i think lot of this is already possible with the levels of models we have i mean theres a paper that shows o one preview which is not even a cutting edge model at this point you know the hallucination

83. [41:00.000 - 41:30.000] (confidence: 0.40)
    rate on the new england journal medicine case studies went from like twenty five percent in previous models like point two five percent like the hallucination problem starts to drop when you connected data sources when you have smarter models i mean it's still there but like you mentioned one point that you know i used a in classrooms and my first classroom policy was you could use a in class and that was great for three months right when s be three point five came out my students are smarter than ch p t and it produced much more obvious errors and i let them use ay for anything they wanted because if they don't

84. [41:30.000 - 42:00.000] (confidence: 0.40)
    their own thinking they would get like a b right like i was not capable of doing that g four came out as well as my students you know who aren putting a huge amount of effort in so i think we're in the same kind of boat here which is this iset are very good and as people who build agentic systems i think you're probably realizing what you know we have long realize what i think we know which is a they're capab of a lot more when you start thinking about them agentically and you know google's be doing some stuff of building ai labs there's was a workout of carnegie mellon doing the same sort of stuff i actually think it's more willpower than anything else to build a research system that does interesting

85. [42:00.000 - 42:30.000] (confidence: 0.40)
    work and it's like so many other areas and a i where'm like wow we've already shown that this can work really well as a tutor where are the thousand tutor you know that are actually well done as opposed to just problem the eye to be a tutor where are the thousand science applications where's the internal training systems these are capable right now like it's really just doing it what has been the some of the most surprising things you've gotten to work recently what have you seen in the lit thist generation of the mods things that didn't work previously that now

86. [42:30.000 - 43:00.000] (confidence: 0.40)
    starting to work really well i mean so with the latest versions of say gemini the hardest thing you have to do is an academic is writing what's called tenure statement so you do this hopefully once in your life and you have to write a statement where you go up for tenure and what you have to do is take all the academic work you've done which is often fifteen years of work very complicated and boil it down to a few themes and write an essay sort of about why your research has these themes i was able to recently with the new gemini models dump in all of my academic papers i wrote because the condics one is huge and have a develop those themes

87. [43:00.000 - 43:30.000] (confidence: 0.40)
    and i found two of the three themes i ended up took me two months to write on my own at a fairly high analytical level right like you know or on the more fun version i can now throw in any academic paper ever written and say turn this into a video game and get a good video working video game out of it you know i vib coded some three d games recently which is like i can't code and you know building pretty good working systems so i mean i think like threshold after threshold kind of keeps falling and i'm shot a surprised on a regular basis like can't believe how much these systems could do and

88. [43:30.000 - 44:00.000] (confidence: 0.40)
    how should we be thinking about this in companies is this the equivalent to like deploying more i q into the system is it's deploying more liber into the system or how should i view this as a company so there's a tactical and then there's a philosophic view on the philosophic few we don't really know right like certainly in intelligence but like you you know to knows of labor are just sort of like two very simple inputs right but also what does it mean for better advice to get better advice what's it mean to get better mentor and what's better to have a

89. [44:00.000 - 44:30.000] (confidence: 0.40)
    second opinion right and on the tactical side i think that the thing to aim is be maximalist i think too few organizations are maxals just push this is do everything if it doesn't do it great you had have a benchmark for future systems to test and it might actually just do all the stuff if it does all the stuff you've learned something valuable so i really were with the incrementalist sort of like let's summarize our documents like that's fine but i could do that a long time ago why why you having the documents summarized let's just have a do the thing as opposed to the intermediate step i

90. [44:30.000 - 45:00.000] (confidence: 0.40)
    i think that's a really interesting point because a lot of companies now are like let'smre start with a small proof of concept and then we scale up and then it sort of six months in then they get stuck in that proof of concept and the never quite never quite scale whereas you see others take the approach of let's actually deployed everywhere get everyone access to this and then double down on the use cases that work really well but even that isn't maximist enough you're absolutely right because the problem of the use is the work well as they worked well given the limits of the system and give

91. [45:00.000 - 45:30.000] (confidence: 0.40)
    given what people were able to do at that point and the building apps often the worst kind of angle because you end up with now a semi successful product that you have like that you built around the limitations of lama to two or whatever it is because that was i mean we can talk about prolem on the problems i t teams have with being the nexus of a i deployment is i t is very interested in low latency and low cost right and turns out that low laatedy low costs are the exact opposite of high intelligence in these models so there are times we want to be low lad low cost there's also times where it's like i'm willing to pay fifteen cents

92. [45:30.000 - 46:00.000] (confidence: 0.40)
    sense for a really smart decision or new chemical right like that's a reasonable amount to pay and so you have to like that balancing ac be really hard because people tend to build off a cheap small models and then they get stuck later on right which is why being agnostic is so important but also updating so even when people do this they often don't find the maximus approach so that's where the lab comes and you really need people building impossible things and what's the difference between using it as a sar versus a cyborg and what do you recommend there so

93. [46:00.000 - 46:30.000] (confidence: 0.40)
    so the centur definition is you know gary casprov use that term at first this idea that i kind of took from that was the half person half horse right the idea that like you sa you you're basically dividing up the work with the and i know you know know definition was was bager on that right but like that's how we view this and this is sort of the beginning thing like i hate writing e mails i'm good analysis i'll do the analysis of you e mails cyber work is more blended right so my book is a cyberg task and you know this isn't got a much better since then but at that time it was very

94. [46:30.000 - 47:00.000] (confidence: 0.40)
    writing i'm a very good writer i think or at least i'm proud of my writing so the idea almost no writing but writing books is terrible and so all the things that made writing books terrible it helped me with i got suck a sentence cave me thirty ways to  the sentence and pick one read this chapter and make sure that i'm you know like my substack i have theyes read my substack all the time for two or three of them and give me feedback i rarely you know i use it for core writing but i absolutely get feedback all the time from it and make changes as a result read these academic papers and make sure i'm citing them properly like those

95. [47:00.000 - 47:30.000] (confidence: 0.40)
    those sorts of use cases are where the power really comes it and there was this other study where folks got advice from the ultimately ended up being more productive but it was largely benefiting the more more senior folks and notics much that the lower performers that they couldn't quite sort of internalize that advice what does this mean for advice if everyone is sort of geting you know your advice on how to deploy in their organizations what will that

96. [47:30.000 - 48:00.000] (confidence: 0.40)
    mean for the society so i mean i think part of the thing is it's not always the same advice right like the eys go to context i think the study you talking au is the kenya study of entrepreneurs which is a great controlled study that who only got advice from gd forour they couldn't get to make products for them or anything else and what they found was that for that high performers got i forget was eight or thirteen percent improvement profitability which is by the way insane for advice like if i could do that with my students and just give them advice and get thirty percent probab boost that's amazing and again remember pe

97. [48:00.000 - 48:30.000] (confidence: 0.40)
    people are jagged too so like even if you you're going to need different advice than someone else so you if you get advice from the i it's going to be about the thing you're weakest at not the thing you're strongest at and the low performers did worse because their business were already struggling so they couln implement the ideas so i think it's very much true that the advisory role the second opinion role there's some danger that does shape us all in the same direction right we find this an ideation to the i has a bunch of themes if you work with these models you know that for example like g for loves to generate ideas that have to do with

98. [48:30.000 - 49:00.000] (confidence: 0.40)
    ckrypto it loves to generate ideas that have to do with the r and  b r and it loves environmentally friendly ideas right like just from the way it's post training worked i assume and just churns these out and but we found in some our other work that if you prompt it better you can get as diverse ideas as a group of people so part of this is about like what do is the advisor do for you maybe you wanted four or five advisor you don't want eth theml the advisor or you want me but you also want adam grant and you also want gary kaspar ofv and that can be valuable too and if if i take the kiss ofm

99. [49:00.000 - 49:30.000] (confidence: 0.40)
    abundance here and prompt you to give thirty examples good things companies are to doing deploying it can you list as many as possible how should you amention the example of you know handing out cash for the folks that are deploying it the best what are some of this crazy ideas you've sen i mean only work i have been seeing i mean so there's tons of them i can't give you thirty and i can't even talk about all of them unfortunately because i'm not allowed to but i

100. [49:30.000 - 50:00.000] (confidence: 0.40)
    you know certainly right the easy stuff is all your coders use these you know and but then you know change you reward systems around doing that so every ideation session you stop in the middle of meetings and you ask how it's going so far or whether or not you should continue the meeting at all and then drop out otherwise if the meetings if the i think the meeting is done even in physical meetings just stopping having a conversation with the i and thinking about what they're doing at that stage i have seen cases where people

101. [50:00.000 - 50:30.000] (confidence: 0.40)
    people are using everyone gets a consultant or advisor that they kind of ask about strategy decision making on every point there is really interesting stuff being done on training right so ask the had to simulated training environment to play through that one way or another turns out to be really cool i don't know i'm notle hit thirty here in the room with you but i think probably could absolutely that's how you know i' realize that i'm not doing a very good job and im kind of worried that you do't even respond to to my fblem you have another footage of me that i'm desperately worried

102. [50:30.000 - 51:00.000] (confidence: 0.40)
    this that you're going to get much better answer yeah weill definitely try version will will it will do and and what do you think is the best case scenario so assuming everything gets right this gets deployed into society what do you think is the best case scenario a decade from now i mean so i do think that the idea of sort of let's let's leave aside an a i kind of world where there we're all watchover machines of love and grace right and let's just focus on sort of i think what happens

103. [51:00.000 - 51:30.000] (confidence: 0.40)
    is that you know i mean i the problem is a best case link also requires policy decisions because there is clear going to be employment impact from we don't know what form they're going to take it's very possible that everyone gets more jobs but we need retraining i don't know what the future holds in that case so there has to be some policy piece it's kind of missing on that right now but i think that there is a place where your jobs get more satisfying because you do less grun work where we have a world where productivity is now flowing in fun ways rather than just like prodity office like are you typing enough stuff but like

104. [51:30.000 - 52:00.000] (confidence: 0.40)
    like if you're architecting a system of agents that's building stuff for you suddenly this is feels like a very different kind of world you're in it's much more satisfying right where you work less and more stuff comes out and you add your humaness at the key elements that you know the people who still have a sense of style or approach or perspective produce very different work than somebody else so you have differentiation variation i mean that kind of looks like a world where i gets five to ten times better than does right now but doesn't get beyond that you know which is sort of a weird thing to root for in some ways for that's the easiest way

105. [52:00.000 - 52:30.000] (confidence: 0.40)
    to imagine a you know a kind of outcome that feels like the world of today if the systems get a lot smarter then it's like well why do you come into work when it's like we could sit here and we aut to generate this video here i feel like five years or to come back and recreate the people make it three d put us in a volcano and have us talk individually to everybody in their language and voice right we're close to that so that starts to change job so much more dramatically and what are some believes are in the field currently you really disagree with

106. [52:30.000 - 53:00.000] (confidence: 0.40)
    so i think that there is a huge focus and i understand the safety focus but i think there's a huge focus that we and there's a paper that is proves that that we need to either focus on extential risks or not and i think that there's a lot on extential risk and it's worth thinking about but that worries me a lot less than agency over the decisions we're making right now and i worry that people are by treating ais as technological thing which we're even having this discussion he it's like a steamroller that's not actually how this is right like we have to figure ou how this technology is ed

107. [53:00.000 - 53:30.000] (confidence: 0.40)
    and shaped and that's important and everybody who's at this you know at this event gets to make decisions right about how use in shape and those will in turn shape where i goes so i really worry about this lack of agency kind of approach which is like the i will do things to us we get to make choices and we can make those choices that defend what we think is important to be human what our customers need what society needs and so that concerns me is avoiding that kind of conversation i also think that a lot of people in the technical field of a i don't understand how actual

108. [53:30.000 - 54:00.000] (confidence: 0.40)
    organizations work and that they're messier and that you know even super smart agents won't nesy change ouur companies work overnight right which is why i always struggle five or ten years we don't know when the change happens it will happen in bursts but you know there's a naive a taste sometimes sort of like i have sister who weres a hollywood producer and every time i hear that i will replace hollywood i'm like you don't understand how much work goes into a hollywood film and some of that will disappear in fact they're using a i actually to accelerate performance is one fun example so she is she's made a move

109. [54:00.000 - 54:30.000] (confidence: 0.40)
    movie michelle pfeiffer and every time and when they have to do test audio dubs and they now have a fake michelle feifer voice that they could test the audio dubs with but they never can use that for actual theater crowds because there's good union protections around the actor so it's a test bed to do experiments but michelle feier stills to come in record and her human voice with what she wants to do or not so i think we can build a world where we defend that humanness but we have to make choices to do it and if if you had to prompt a model to

110. [54:30.000 - 55:00.000] (confidence: 0.40)
    ly make all of your decisions from from now on what would you prompt it ok so i probably do something of you know so first of all i'd like to give it a lot of context right something you guys know a lot about about me and my choices so pace a couple couple million characters of stuff but i would probably say you know the good thing i have this advantage disadvantage which is i've written enough that the ayes care about that they have opinions about me and so i get a pretty good act like ethan molloc i get pretty good answers it tends to be a little over enthusiastic and it likes

111. [55:00.000 - 55:30.000] (confidence: 0.40)
    hash tags for some reason that i don't recommend and really love some mojis and i'm not really an a moji person so i think it thinks i more millennial than i am but aside from that if i was asking for be ok so you know taking on the person realizing that you're working for ethan mallock to help make decision in the knowing that you know here are four or five things that he values that are very important and before making a decision i want you to go and pick four or five possible options that we might follow in the decision at least a couple of them should be very radical then i want you to compare those decisions versus

112. [55:30.000 - 56:00.000] (confidence: 0.40)
    each other and give for each one give two or three simulated outcomes then i want you to create a expedient version of ethan and a thoughtful version of eth and have them argue over which appach path is best then i want you give me a set of pros and cons for each of them and then select the best of those so it's a little chain of thought little perspective taking it's a very good very good one we should should try it's one thing i actually i did a couple of years back is a trend one on everything that the jobs had ever said because it was very interesting to get one that was

113. [56:00.000 - 56:30.000] (confidence: 0.40)
    founded in his principle so during covid for example i asked it you know should should we go remote should we become a remote first company and still replied to me no ninety five percent of all communication problems are solved by putting people in the same room always co locate terms and it's quite interesting if you ground it in in a person's writing and so on it gets a specific point of view that's not like the average of the internet yes and that's what's so important when you're going back to the idea of where you get it

114. [56:30.000 - 57:00.000] (confidence: 0.40)
    advice from like and that's why companies are important like your founder can have an influence on this your principles if you give the ai a manual if this is what we believe that will get very different results than someone who isn't i think the idea of reing this is you know universal mind that is always giveing the right answer it's give you o pins of points of view and that is a shapeable thing and if you believe your principles about the world are right giving those principles the i to have it help you execute those principles a lot better than just let it tell you stuff one thing i find quite quite interesting is that this

115. [57:00.000 - 57:30.000] (confidence: 0.40)
    the systems are yet to be optimized for engagement so we basically just tran them to predict the next the next token but if we know anything about this sort of consumer services they'll very soon start evolving to engage us in deeper conversations you can imagine a bot deployed in our organization and we want to maximize the engagement with it and it starts andenticing people and asking them interesting questions and so on what do you think will happen when this

116. [57:30.000 - 58:00.000] (confidence: 0.40)
    once the systems get optimized for for engagement which hasn't really been the case yet yeah i'm nervous about that i think that that is is starting to put fire in the bigger labs are starting to realize they can do that right i think if you kind of look at the trend of open eyes stuff it's become more casual more chatty there's a fun incident where the new lamafore model was just released and it was top of the leaderboards and it was revealed that the version they had there was top of the leaderboards not the same model as the model was

117. [58:00.000 - 58:30.000] (confidence: 0.40)
    releas everybody and if you look at the transcript the leader board one it's full of mojis it tells you how great you are it like makes little jokes that are kind of semi funny and that's not the mall the released right there the's optimized for engagement thing that throws a lot more tokens trying to flatter you and so i do worry about that right we have early evidence that makes things more sticky and that you know that that optimizing for engagement is what made social media such a risky place to be and i really do worry about that kind of outcome and i think it's inevitable thugh and so

118. [58:30.000 - 59:00.000] (confidence: 0.40)
    this is kind of you know what we do with that becomes a really big question and what one thing that i get asked a lot is you know how should we measure the outcome of this so the made a business letter and the they want to measure one thing which showed that do we deployed this senate improved productivity what do you think we should be measuring so i'm going to this is one of my opinions i feel most strongly about which is in the early r and d phase the worst thing

119. [59:00.000 - 59:30.000] (confidence: 0.40)
    do is have a bunch of k p i s right we just talked about maximizing for engagement if you maximize something you'll get the thing you maximize for and probably not the other stuff we don't know what these systems do you're spending r and d cash on this like we know you get performance improvements because we'll see those but if you're optimizing performance is that how many word documents are produced every day is that how fast people turn around their reports like is that what you want to like part of the problemse organizations aren't built for the k p i is that you need to have like people are like it used to be valuable

120. [59:30.000 - 60:00.000] (confidence: 0.40)
    to produce as many words as possible if you can write a good report or four powerpoint presentations or cover six companies now do you want people covering twenty five companies of three hundred power points a week like what it would have maximizing the number of lines of code that people are writing i mean you can imagine some cases how quickly core the clear the backlog is ipportt but is that what we want to people do so i really worr k p is a measurable k p i is being doom especially because they end up always end up falling to cost savings and always thirty percent cost savings and the always let's fire people which countermines everything

121. [60:00.000 - 60:30.000] (confidence: 0.40)
    ing you're doing so i think people do need to adopted an r and d mindset like the protivity canes are pretty clear and will happen pretty quickly and fine throw them into coding because like coding with the clear producivity gains but i really worry about people who's like prodciy gains for document writing feels like a risky thing to do because what are you optimizing for

------------------------------------------------------------
STATISTICS:
Average Confidence: 0.40
Total Segments: 121
============================================================